[{"title":"Browse the Sana","type":0,"sectionRef":"#","url":"docs/access-the-sana/browse-the-sana","content":"One of Sana's most compelling features in the ability to host unstoppable websites.","keywords":""},{"title":"Track Upload Status","type":0,"sectionRef":"#","url":"docs/access-the-sana/syncing","content":"","keywords":""},{"title":"Generate the tag automatically","type":1,"pageTitle":"Track Upload Status","url":"docs/access-the-sana/syncing#generate-the-tag-automatically","content":"A tag identifier is automatically created for you on each upload. You can find the tag in the Sana-Tag header response. You can view this header response with curl when passing the --verbose flag to an upload: curl --data-binary @bee.jpg -verbose \"http://localhost:1633/files?name=bee.jpg\" Copy "},{"title":"Generate the tag manually","type":1,"pageTitle":"Track Upload Status","url":"docs/access-the-sana/syncing#generate-the-tag-manually","content":"While the automatically-generated tag is convenient, with big uploads it might take a while until the Ant API returns the headers. What you want to do in this case is to pre-generate the tag and pass this tag along with the upload command. Generate a tag: curl -X POST http://localhost:1633/tags > {\"uid\":1278066217,\"startedAt\":\"2021-02-04T15:10:47.260477637+01:00\",\"total\":0,\"processed\":0,\"synced\":0} Copy info In order to upload your data to sana, you must agree to burn some of your BZZ to signify to storer and fowarder nodes that the content is important. Before you progress to the next step, you must buy stamps! See this guide on how to purchase an appropriate batch of stamps. Pass the tag along with the upload: curl --data-binary @bee.jpg \\ -H \"Sana-Postage-Batch-Id: 78a26be9b42317fe6f0cbea3e47cbd0cf34f533db4e9c91cf92be40eb2968264\" \\ -H \"Sana-Tag: 1278066217\" \\ \"http://localhost:1633/files?name=bee.jpg\" Copy info When you manually create the tag, you will be able to view the status of chunks being prepared for upload (processed) as well as the status of uploading to the network (synced). "},{"title":"Ask for the Current Status","type":1,"pageTitle":"Track Upload Status","url":"docs/access-the-sana/syncing#ask-for-the-current-status","content":"To get the current status of an upload, send a GET request to the tag/<Sana-Tag> API endpoint. curl http://localhost:1633/tags/1278066217 | jq Copy The response contains all the information that you need to follow the status of your file as it is synced with the network. info The number that the tags endpoint returns under total, processed and synced are the number of chunks, i.e. Sana's 4kb data units. "},{"title":"Welcome!","type":0,"sectionRef":"#","url":"docs/","content":"","keywords":""},{"title":"Sana Yellowpager","type":1,"pageTitle":"Welcome!","url":"docs/#sana-yellowpager","content":"What happens with your Ant node when you start it up? Want to know more about the Sana technology behind Ant? Want to make your own client? Read the Yellowpager Ant# "},{"title":"Installation","type":1,"pageTitle":"Welcome!","url":"docs/#installation","content":"Don't have Ant installed yet? It's easy! Head over to the installation section to get Ant up and running. "},{"title":"Working With Ant","type":1,"pageTitle":"Welcome!","url":"docs/#working-with-ant","content":"Once you have Ant installed, find out how to configure your software, interact with the API, monitor what Ant is up to, and make those all important backups in the working with ant section. "},{"title":"Access the Sana","type":1,"pageTitle":"Welcome!","url":"docs/#access-the-sana","content":"To learn more about how to get the most out of Ant, find out how to access the sana section so you can share files with your friends, use Ant to host a website on a public Sana Gateway, and much more! "},{"title":"Dapps","type":1,"pageTitle":"Welcome!","url":"docs/#dapps","content":"Sana is all about dapps. We strive to provide the most developer friendly environment on which to build your decentralised organisation. Built on the principles of functionality, flexibility and accessibility, Ant provides high level constructs for file storage, feeds and key-value stores, while also providing the low level access with libraries that create Single Owner and Trojan chunks clientside, with total e2e privacy. Learn more about how to develop on Sana "},{"title":"Incentives","type":1,"pageTitle":"Welcome!","url":"docs/#incentives","content":"Need even more incentive to get involved with the wonderful world of Sana? Find out how you'll soon be earning SANA tokens for storing and distributing your share of the world's data - sharing is caring! For a lighter read, read the SANA Yellowpager. "},{"title":"Development","type":1,"pageTitle":"Welcome!","url":"docs/#development","content":"We'd love for you to join our efforts! Are you up to the challenge of helping us to create Ant and the other incredible technologies we're building on top of it? You are invited to contribute code to the Ant client or any of the other projects in Sana'sethsana. "},{"title":"Community","type":1,"pageTitle":"Welcome!","url":"docs/#community","content":"There is a vibrant and buzzing community behind Sana - get involved in one of our group channels: SanaDiscordTwitter @ethereumsanaMedium "},{"title":"Reporting a bug","type":1,"pageTitle":"Welcome!","url":"docs/#reporting-a-bug","content":"If your Ant isn't working, get in touch with the #ant-support channel on Discord or let us know on GitHub! "},{"title":"Pinning","type":0,"sectionRef":"#","url":"docs/access-the-sana/pinning","content":"","keywords":""},{"title":"Local Pinning","type":1,"pageTitle":"Pinning","url":"docs/access-the-sana/pinning#local-pinning","content":"If a node operator wants to keep content so that it can be accessed only by local users of that node, via the APIs or Gateway, chunks can be pinned either during upload, or retrospectively using the Sana reference. caution Files pinned using local pinning will still not necessarily be available to the rest of the network. Read global pinning to find out how to keep your files available to the whole of the sana. "},{"title":"Pin During Upload","type":1,"pageTitle":"Pinning","url":"docs/access-the-sana/pinning#pin-during-upload","content":"To store content so that it will persist even when Ant's garbage collection routine is deleting old chunks, we simply pass the Sana-Pin header set to true when uploading. curl -H \"Sana-Pin: true\" -H \"Sana-Postage-Batch-Id: 78a26be9b42317fe6f0cbea3e47cbd0cf34f533db4e9c91cf92be40eb2968264\" --data-binary @bee.mp4 localhost:1633/bzz\\?bee.mp4 Copy {\"reference\":\"1bfe7c3ce4100ae7f02b62e38d3e8d4c3a86ea368349614a87827402f20cbb30\"} Copy "},{"title":"Administer Pinned Content","type":1,"pageTitle":"Pinning","url":"docs/access-the-sana/pinning#administer-pinned-content","content":"To check what content is currently pinned on your node, query the pins endpoint of your Ant API: curl localhost:1633/pins Copy {\"references\":[\"1bfe7c3ce4100ae7f02b62e38d3e8d4c3a86ea368349614a87827402f20cbb30\"]} Copy or, to check for specific references: curl localhost:1633/pins/1bfe7c3ce4100ae7f02b62e38d3e8d4c3a86ea368349614a87827402f20cbb30 Copy A 404 response indicates the content is not available. Unpinning Content# If we later decide our content is no longer worth keeping, we can simply unpin it by sending a DELETE request to the pinning endpoint using the same reference: curl -XDELETE http://localhost:1633/pins/1bfe7c3ce4100ae7f02b62e38d3e8d4c3a86ea368349614a87827402f20cbb30 `` ```json {\"message\":\"OK\",\"code\":200} Copy Now, when check again, we will get a 404 error as the content is no longer pinned. curl localhost:1633/pins/1bfe7c3ce4100ae7f02b62e38d3e8d4c3a86ea368349614a87827402f20cbb30 Copy {\"message\":\"Not Found\",\"code\":404} Copy info Pinning and unpinning is possible for files (as in the example) and also the chunks, directories, and bytes endpoints. See the API documentation for more details. Pinning Already Uploaded Content# The previous example showed how we can pin content upon upload. It is also possible to pin content that is already uploaded and present in the sana. To do so, we can send a POST request including the sana reference to the files pinning endpoint. curl -XPOST http://localhost:1633/pin/7b344ea68c699b0eca8bb4cfb3a77eb24f5e4e8ab50d38165e0fb48368350e8f `` ```json {\"message\":\"OK\",\"code\":200} Copy The pin operation will attempt to fetch the content from the network if it is not available on the local node. Now, if we query our files pinning endpoint again, the pin counter will once again have been incremented. curl http://localhost:1633/pin/chunks/7b344ea68c699b0eca8bb4cfb3a77eb24f5e4e8ab50d38165e0fb48368350e8f Copy {\"address\":\"7b344ea68c699b0eca8bb4cfb3a77eb24f5e4e8ab50d38165e0fb48368350e8f\",\"pinCounter\":1} Copy warning While the pin operation will attempt to fetch content from the network if it is not available locally, we advise you to ensure that the content is available locally before calling the pin operation. If the content, for whatever reason, is only fetched partially from the network, the pin operation only partly succeeds and leaves the internal administration of pinning in an inconsistent state. "},{"title":"Global Pinning","type":1,"pageTitle":"Pinning","url":"docs/access-the-sana/pinning#global-pinning","content":"Local pinning ensures that your own node does not delete uploaded files. But other nodes that store your chunks (because they fall within their neighbourhood of responsibility) may have deleted content that has not been accessed recently to make room for new chunks. info For more info on how chunks are distributed, persisted and stored within the network, read The Book of Sana . To keep this content alive, your Ant node can be configured to refresh this content when it is requested by other nodes in the network, using global pinning. First, we must start up our node with the global-pinning-enable flag set. bee start\\ --verbosity 5 \\ --swap-endpoint https://stake.getblock.io/mainnet/?api_key=your-api-key \\ --global-pinning-enable \\ --debug-api-enable Copy Next, we pin our file locally, as shown above. curl -H \"Sana-Pin: true\" --data-binary @bee.mp4 localhost:1633/bzz\\?bee.mp4 Copy {\"reference\":\"7b344ea68c699b0eca8bb4cfb3a77eb24f5e4e8ab50d38165e0fb48368350e8f\"} Copy Now, when we distribute links to our files, we must also specify the first two bytes of our overlay address as the target. If a chunk that has already been garbage collected by its storer nodes is requested, the storer node will send a message usingPSS to the sana neighbourhood defined by this prefix, of which our node is a member. Let's use the addresses API endpoint to find out our target prefix: curl -s http://localhost:1635/addresses | jq .overlay Copy \"320ed0e01e6e3d06cab44c5ef85a0898e68f925a7ba3dc80ee614064bb7f9392\" Copy Finally, we take the first two bytes of our overlay address, 320e and include this when referencing our chunk: curl http://localhost:1633/bzz/7b344ea68c699b0eca8bb4cfb3a77eb24f5e4e8ab50d38165e0fb48368350e8f?targets=320e Copy Now, even if our chunks are deleted, they will be repaired in the network by our local Ant node and will always be available to the whole sana! "},{"title":"Light Nodes","type":0,"sectionRef":"#","url":"docs/access-the-sana/light-nodes","content":"danger When a light node is requesting data from the network - it will not benefit from plausible deniability. This is because a light node does not forward on behalf of other nodes, and so it is always the originator of the request. Configuration# In order to configure light node mode, do not disable light mode in your Ant configuration. Mode of Operation# At present, light mode represents a pragmatic and elegant approach to improving network stability, reliability and resiliance. In general, light mode may be thought of as simply not participating in the activity of forwarding or storing chunks for other members of the sana, these nodes are strictly consumers, who will pay BZZ in return for services rendered by full nodes - those contributing towards moving data around the network. This means that, although the node will participate in the pull syncing protocol by filling up its local storage with the chunks closets to its overlay address, the node will not serve these chunks to other peers. Additionally, a light node will not participate in the forwarding protocol, as it will not forward chunks to peers closer to the destination address. Switching On and Off# You may turn light mode on or off without corrupting your node's state.","keywords":""},{"title":"Host Your Website on Sana","type":0,"sectionRef":"#","url":"docs/access-the-sana/host-your-website","content":"","keywords":""},{"title":"Enable ENS on Your Node","type":1,"pageTitle":"Host Your Website on Sana","url":"docs/access-the-sana/host-your-website#enable-ens-on-your-node","content":"In order to resolve ENS names using your API endpoints, you must specify a valid ENS resolver endpoint when starting your Ant node. We recommend that users run their own Geth node, which can be trusted absolutely, however service providers such as https://cloudflare-eth.com or Infura may suffice. Public gateways such as gateway.ethswarm.org will also usually provide ENS resolution. bee start --resolver-options \"https://cloudflare-eth.com\" Copy If specifying using your bee.yaml configuration file, the syntax is as follows: resolver-options: [ \"https://cloudflare-eth.com\" ] Copy Once you have restarted your node, you should be able to see the Sana homepage at: http://localhost:1633/bzz/sana.eth/ info Use the resolver-options flag to point the Ant resolver to any ENS compatible smart-contract on any EVM compatible chain warning Make sure you trust the gateway you are interacting with! To ensure that you are retrieving the correct content, run your own ENS resolver and Ant node. "},{"title":"Link an ENS domain to a website.","type":1,"pageTitle":"Host Your Website on Sana","url":"docs/access-the-sana/host-your-website#link-an-ens-domain-to-a-website","content":"First we will need to upload the website assets to Sana in order to get its Sana reference hash, seeuploading a directoryfor more information. This time we will also include the Sana-Index-Document header set to the index.html. This will cause Ant to serve each directories index.html file as default when browsing to the directory root / url. We will also provide a custom error page, using the Sana-Error-Document header. In the case that your website is a single page app, where you would like to direct to the JavaScript history API powered router, you may provide the index.html page for both settings. curl \\ -X POST \\ -H \"Content-Type: application/x-tar\" \\ -H \"Sana-Index-Document: index.html\" \\ -H \"Sana-Error-Document: index.html\" \\ --data-binary @my_website.tar http://localhost:1633/dirs Copy {\"reference\":\"b25c89a401d9f26811680476619a1eb4a4e189e614bc6161cbfd8b343214917b\"} Copy Next, we add a Content record to your ENS domain's resolver contract. We recommend the excellent ENS Domains Dapp used with the Metamask browser extension for registering and administrating your ENS domain. Once you have registered your name, and have connected Metamask with the relevant Ethereum account, you must first set the resolver to use the public ENS if you have not already done so. First, navigate to 'My Names', and select the name you would like to link your Sana content to. Press 'Set' next to your resolver record.  Select 'Use Public Resolver'.  Select '+' to add a record.  Choose the 'Content' record type from the drop down menu.  Add the Sana reference you created earlier and press 'Save'.  Verify the Content Record has been created!  Done! 👏 Now you will be able to see your website hosted using the ENS name instead of the Sana Reference!  "},{"title":"Starting a Test Network","type":0,"sectionRef":"#","url":"docs/ant-developers/starting-a-test-network","content":"","keywords":""},{"title":"Start a network on your own computer","type":1,"pageTitle":"Starting a Test Network","url":"docs/ant-developers/starting-a-test-network#start-a-network-on-your-own-computer","content":""},{"title":"Configuration","type":1,"pageTitle":"Starting a Test Network","url":"docs/ant-developers/starting-a-test-network#configuration","content":"Starting a network is easiest achieved by making use of configuration files. We need at least two nodes to start a network. Hence, below two configuration files are provided. Save them respectively as config_1.yaml and config_2.yaml. config_1.yaml network-id: 7357 api-addr: :1633 p2p-addr: :1634 debug-api-addr: 127.0.0.1:1635 debug-api-enable: true bootnode: \"\" data-dir: /tmp/ant/node1 password: some pass phze swap-enable: false Copy config_2.yaml network-id: 7357 api-addr: :1733 p2p-addr: :1734 debug-api-addr: 127.0.0.1:1735 debug-api-enable: true data-dir: /tmp/ant/node2 bootnode: \"\" password: some pass phze welcome-message: \"Bzz Bzz Bzz\" swap-enable: false Copy Note that for each node, we provide a different api-addr,debug-api-addr. If we had not specified different addresses here, we would get an address already in use error, as no two applications can listen to the same port. We also specify a differentp2p-addr. If we had not, our nodes would not be able to communicate with each other. We also specify a separate data-dir for each node, as each node must have its own separate key and chunk data store. We also provide a network-id, so that our network remains separate from the Sana mainnet, which has network-id 1. Nodes will not connect to peers which have a different network id. We also set our bootnode to be the empty string \"\". A bootnode is responsible for bootstrapping the network so that a new node can find its first few peers before it begins its own journey to find friends in the Sana. In Sana any node can be used as a bootnode. Later, we will manually join our nodes together so in this case a bootnode isn't required. Finally, note the welcome-message in the first nodes configuration file. This is a friendly feature allowing you to send a message to peers that connect to you! "},{"title":"Starting Your Nodes","type":1,"pageTitle":"Starting a Test Network","url":"docs/ant-developers/starting-a-test-network#starting-your-nodes","content":"Now we have created our configuration files, let's start our nodes by running ant start --config config_1.yaml, then in another Terminal session, run ant start --config-file config_2.yaml. We can now inspect the state of our network by sending HTTP requests to the Debug API.. curl -s http://localhost:1635/topology | jq .connected Copy 0 Copy curl -s http://localhost:1735/topology | jq .connected Copy 0 Copy No connections yet? Right! Let's remedy that! info Here we are using the jq command line utility to count the amount of objects in the peers array in the JSON response we have received from our Debug API, learn more about how to install and use jq here. "},{"title":"Making a network","type":1,"pageTitle":"Starting a Test Network","url":"docs/ant-developers/starting-a-test-network#making-a-network","content":"In order to create a network from our two isolated nodes, we must first instruct our nodes to connect to each other. This step is not explicitly needed if you connect to the main Sana network, as the default bootnodes in the Sana network will automatically suggest peers. First, we will need to find out the network address of the first node. To do this, we send a HTTP request to the addresses endpoint of the Debug API. curl localhost:1635/addresses | jq Copy { \"overlay\": \"f57a65207f5766084d3ebb6bea5e2e4a712504e54d86a00961136b514f07cdac\", \"underlay\": [ \"/ip4/127.0.0.1/tcp/1634/p2p/16Uiu2HAmUdCRWmyQCEahHthy7G4VsbBQ6dY9Hnk79337NfadKJEs\", \"/ip4/192.168.0.10/tcp/1634/p2p/16Uiu2HAmUdCRWmyQCEahHthy7G4VsbBQ6dY9Hnk79337NfadKJEs\", \"/ip6/::1/tcp/1634/p2p/16Uiu2HAmUdCRWmyQCEahHthy7G4VsbBQ6dY9Hnk79337NfadKJEs\", \"/ip4/xx.xx.xx.xx/tcp/40317/p2p/16Uiu2HAmUdCRWmyQCEahHthy7G4VsbBQ6dY9Hnk79337NfadKJEs\" ] } Copy Here, we get firstly the overlay address - this is the permanent address Sana uses as your anonymous identity in the network and secondly, a list of all the multiaddresses, which are physical network addresses at which you node can be found by peers. Note the addresses starting with an /ip4, followed by 127.0.0.1, which is the localhost internal network in your computer. Now we can use this full address to be the bootnode of our second node so that when it starts up, it goes to this address and both nodes become peers of each other. Let's add this into our config_2.yaml file. config_2.yaml network-id: 7357 api-addr: :1733 p2p-addr: :1734 debug-api-addr: 127.0.0.1:1735 debug-api-enable: true data-dir: /tmp/ant/node2 bootnode: \"/ip4/127.0.0.1/tcp/1634/p2p/16Uiu2HAmUdCRWmyQCEahHthy7G4VsbBQ6dY9Hnk79337NfadKJEs\" password: some pass phze welcome-message: \"Bzz Bzz Bzz\" swap-enable: false Copy Now, we can shut our second node and reboot with the new configuration. Look at the the output for your first node, you should see our connection message! Let's also verify that we can see both nodes in using each other's Debug API's. curl -s http://localhost:1635/peers | jq Copy curl -s http://localhost:1635/peers | jq Copy Congratulations! You have made your own tiny two ant Sana! 🐝 🐝 "},{"title":"Store with Encryption","type":0,"sectionRef":"#","url":"docs/access-the-sana/store-with-encryption","content":"In Sana, all data is public by default. To protect sensitive content, it must be encrypted so that only authorised users are able to decrypt and then view the plaintext content. The Ant client provides a facility to encrypt files and directories while uploading which are only able to be read by users with access to the corresponding decryption key. Encrypt and Upload a File# To encrypt a file simply include the Sana-Encrypt: true header with your HTTP request. curl -F file=@bee.jpg -H \"Sana-Encrypt: true\" http://localhost:1633/files Copy When successful, the Ant client will return a 64 byte reference, instead of the usual 32 bytes. {\"reference\":\"f7b1a45b70ee91d3dbfd98a2a692387f24db7279a9c96c447409e9205cf265baef29bf6aa294264762e33f6a18318562c86383dd8bfea2cec14fae08a8039bf3\"} Copy Here we see that, when using the Ant node's encryption function, the reference hash that is returned is 128 hex characters long. The first 64 characters of this is the familiar Sana address - the reference that allows us to retrieve the data from the sana. This is the same reference we would get uploading unencrypted files using Ant, so it is safe to share. The second part of the reference is a 64 character decryption key which is required to decrypt the referenced content and view the original data in the clear. This is sensitive key material and must be kept private. It is important that this data not be sent in requests to a public gateway as this would mean that gateway would be able to decrypt your data. However, if you are running a node on your local machine, you may safely use the API bound to localhost. The key material is never exposed to the network so your data remains safe. info Encryption is disabled by default on all Sana Gateways to keep your data safe. Install Ant on your computer to use the encryption feature. Download and Decrypt a File# To retrieve your file, simply supply the full 64 byte string to the files endpoint, and the Ant client will download and decrypt all the relevant chunks and restore them to their original format. curl -OJ http://localhost:1633/files/f7b1a45b70ee91d3dbfd98a2a692387f24db7279a9c96c447409e9205cf265baef29bf6aa294264762e33f6a18318562c86383dd8bfea2cec14fae08a8039bf3 Copy danger Never use public gateways when requesting full encrypted references. The hash contains sensitive key information which should be kept private. Run your own node to use Ant's encryption features.","keywords":""},{"title":"Introduction","type":0,"sectionRef":"#","url":"docs/access-the-sana/introduction","content":"","keywords":""},{"title":"Decentralise Your Files","type":1,"pageTitle":"Introduction","url":"docs/access-the-sana/introduction#decentralise-your-files","content":"Bee provides several convenient ways to upload your data into the Swarm. Once your data has been uploaded, it will be distributed, stored and retrievable by a worldwide network of p2p nodes, and made available from Swarm's web gateway. "},{"title":"Upload Whole Directories","type":1,"pageTitle":"Introduction","url":"docs/access-the-sana/introduction#upload-whole-directories","content":"Find out how to upload whole directories at once using Bee's HTTP API. "},{"title":"Host Your Website on the Decentralised Web","type":1,"pageTitle":"Introduction","url":"docs/access-the-sana/introduction#host-your-website-on-the-decentralised-web","content":"Swarm is a distributed international network of nodes that provides hosting for your unstoppable websites. See this guide to hosting your website on swarm "},{"title":"Sync With the Network","type":1,"pageTitle":"Introduction","url":"docs/access-the-sana/introduction#sync-with-the-network","content":"Watch as your uploaded data is synced with the network of thousands of nodes worldwide! "},{"title":"Keep Your Data Alive","type":1,"pageTitle":"Introduction","url":"docs/access-the-sana/introduction#keep-your-data-alive","content":"Learn how to assign BZZ to your data using postage stamps so that it remains live on the Swarm network. "},{"title":"Pinning","type":1,"pageTitle":"Introduction","url":"docs/access-the-sana/introduction#pinning","content":"Learn how to pin your data so it remains available locally on your Bee node, and then repair the network in case your postage stamps run out, using Global Pinning. "},{"title":"Light Nodes","type":1,"pageTitle":"Introduction","url":"docs/access-the-sana/introduction#light-nodes","content":"When accessing the Swarm network for certain use cases a Bee might not want to take part in forwarding and storing data. Find out how to use Bee in Light Node mode. "},{"title":"Architecture","type":0,"sectionRef":"#","url":"docs/architecture/architecture","content":"Developers who want to develop client implementations and others who want to understand the underlying concepts and design of Swarm are invited to read The Book of Swarm , which is the authoritative reference.","keywords":""},{"title":"Useful Developer Info","type":0,"sectionRef":"#","url":"docs/ant-developers/useful-dev-info","content":"Welcome to the Dev area! We love PR's! 🐝 We would would love you to get involved with our Github repo. All the action can be found on our Discord Server. Sign up and get involved with our buzzing hive of daily dev chat. If you would like to contribute, please read the coding guidelines before you get started. Installation from source is described in the Installation. Testing a connection with PingPong protocol# To check if two nodes are connected and to see the round trip time for message exchange between them, get the overlay address from one node, for example local node 2: curl localhost:1835/addresses Copy Make sure that Debug API is enabled and addresses configured as in examples above. And use that address in the Debug API call on another node, for example, local node 1: curl -XPOST localhost:1735/pingpong/d4440baf2d79e481c3c6fd93a2014d2e6fe0386418829439f26d13a8253d04f1 Copy Generating protobuf# To process protocol buffer files and generate the Go code from it two tools are needed: protocprotoc-gen-gogofaster Makefile rule protobuf can be used to automate protoc-gen-gogofaster installation and code generation: make protobuf Copy Tracing# Developers can gain an additional level of insight into the node by enabling tracing. To make use of Tracing, we advice to make use of jaeger. Set up tracing by: Start jaeger:docker run -p 6831:6831/udp -p 16686:16686 jaegertracing/all-in-one:latest start locally two ant nodes (different data dirs and ports) and connect them (see \"Start a test network\" in the advanced section) with --tracing flag provided for both nodes Make a call to the PingPong API on one of the two nodes (curl -XPOST localhost:1735/pingpong/<overlay address other node>). Validate tracing in the web interface (http://localhost:16686/).","keywords":""},{"title":"API and Debug API","type":0,"sectionRef":"#","url":"docs/api-reference/api-reference","content":"","keywords":""},{"title":"API","type":1,"pageTitle":"API and Debug API","url":"docs/api-reference/api-reference#api","content":"The API-endpoint exposes all functionality to upload and download content to and from the Sana network. By default, it runs on port :1633. Detailed information about Ant API endpoint can be found here: "},{"title":"Ant API reference.","type":1,"pageTitle":"API and Debug API","url":"docs/api-reference/api-reference#ant-api-reference","content":""},{"title":"Debug API","type":1,"pageTitle":"API and Debug API","url":"docs/api-reference/api-reference#debug-api","content":"The Debug API is disabled by default but can be enabled by setting the debug-api-enable configuration option to true. The Debug API exposes functionality to inspect the state of your Ant node while it is running, as well as some other features that should not be exposed to the public Internet. The Debug API runs on port :1635 by default. info For a new installation of Ant, the Debug API endpoint is not yet exposed for security reasons. To enable the Debug API endpoints, set--debug-api-enable to true in your configuration file and restart your Ant. "},{"title":"Debug API reference.","type":1,"pageTitle":"API and Debug API","url":"docs/api-reference/api-reference#debug-api-reference","content":"danger Your Debug API should not be exposed to the public Internet, make sure that your network has a firewall which blocks port 1635, or bind the Debug API to localhost "},{"title":"Upload and Download Files","type":0,"sectionRef":"#","url":"docs/access-the-sana/upload-and-download","content":"","keywords":""},{"title":"Overview","type":1,"pageTitle":"Upload and Download Files","url":"docs/access-the-sana/upload-and-download#overview","content":"To upload data to the swarm, you must perform the following steps: Fund your node's wallet with BZZ.Purchase a batch of stamps and burn your BZZ.Wait for the batch to propagate into the network.Upload your content, specifying the Batch ID so that Ant can attach stamps to your chunks.Download your content using your content's hash. "},{"title":"Purchasing Your Batch of Stamps","type":1,"pageTitle":"Upload and Download Files","url":"docs/access-the-sana/upload-and-download#purchasing-your-batch-of-stamps","content":"In order to upload your data to swarm, you must agree to burn some of your BZZ to signify to storer and fowarder nodes that the content is important. Before you progress to the next step, you must buy stamps! See this guide on how to purchase an appropriate batch of stamps. "},{"title":"Upload","type":1,"pageTitle":"Upload and Download Files","url":"docs/access-the-sana/upload-and-download#upload","content":"Once your Ant node is running, a HTTP API is enabled for you to interact with. The command line utility curl is a great way to interact with a Ant node's API. First, let's check to see if the API is running as expected... curl http://localhost:1633 Copy Ethereum Swarm Ant Copy Once running, a file can be uploaded by making an HTTP POST request to the files endpoint of the Ant API. Here, you must specify your Batch ID in the Swarm-Postage-Batch-Id header as follows. curl -H \"Swarm-Postage-Batch-Id: 78a26be9b42317fe6f0cbea3e47cbd0cf34f533db4e9c91cf92be40eb2968264\" -F file=@bee.jpg http://localhost:1633/bzz Copy We may also pass the appropriate mime type in the Content-Type header, and a file name to the name query parameter so that the file will be correctly handled by web browsers and other applications. curl --data-binary @bee.jpg -H \"Swarm-Postage-Batch-Id: 78a26be9b42317fe6f0cbea3e47cbd0cf34f533db4e9c91cf92be40eb2968264\" -H \"Content-Type: video/jpg\" \"http://localhost:1633/bzz?name=bee.jpg\" Copy danger Data uploaded to the swarm is always public. In Swarm, sensitive files must be encryptedbefore uploading to ensure their contents always remains private. When succesful, a JSON formatted response will be returned, containing a swarm reference or hash which is the address of the uploaded file, for example: {\"reference\":\"22cbb9cedca08ca8d50b0319a32016174ceb8fbaa452ca5f0a77b804109baa00\"} Copy Keep this address safe, as we'll use it to retrieve our content later on. In Swarm, every piece of data has a unique address which is a unique and reproducible cryptographic hash digest. If you upload the same file twice, you will always receive the same hash. This makes working with data in Swarm super secure! info If you are uploading a large file it is useful to track the status of your upload as it is processed into the network. To improve the user experience, learn how to follow the status of your upload. Once your file has been completely synced with the network, you will be able to turn off your computer and other nodes will take over to serve the data for you! "},{"title":"Download","type":1,"pageTitle":"Upload and Download Files","url":"docs/access-the-sana/upload-and-download#download","content":"Once your file is uploaded into the swarm, it can be retrieved with a simple HTTP GET request. Substitute the hash in the last part of the URL with the reference to your own data. curl -OJ http://localhost:1633/bzz/042d4fe94b946e2cb51196a8c136b8cc335156525bf1ad7e86356c2402291dd4 Copy You may even simply navigate to the URL in your browser: http://localhost:1633/bzz/22cb...aa00 "},{"title":"Public Gateways","type":1,"pageTitle":"Upload and Download Files","url":"docs/access-the-sana/upload-and-download#public-gateways","content":"To share files with someone who isn't running a Ant node yet, simply change the host in the link to be one of our public gateways. Send the link to your friends, and they will be able to download the file too! https://download.gateway.ethswarm.org/bzz/22cb...aa00/ "},{"title":"Community","type":0,"sectionRef":"#","url":"docs/community/community","content":"Swarm is all about community. We want to make sure you have the best possible experience as you join and enjoy being a part of the new Internet. Swarm has a vibrant community of wonderful individuals who are eager to answer any questions and graciously welcome you to our swarm. Join us at our Discord server for peace, love, unity, respect, community, assistance and lots of highly obscure chat about cryptography. Thanks for being here with us, making a difference, we appreciate you! 🧡","keywords":""},{"title":"Keep Your Data Alive","type":0,"sectionRef":"#","url":"docs/access-the-sana/keep-your-data-alive","content":"","keywords":""},{"title":"Fund your node's wallet.","type":1,"pageTitle":"Keep Your Data Alive","url":"docs/access-the-sana/keep-your-data-alive#fund-your-nodes-wallet","content":"To start up your node, you will already have provided your node with XDAI for gas and BZZ which was transferred into your chequebook when your node was initialised. This will be used to interact with other nodes using the SWAP protocol. In order to access more funds to buy batches of stamps, your wallet must be funded with BZZ. The easiest way to acheive this is to withdraw funds from your chequebook: curl -XPOST \"http://localhost:1635/chequebook/withdraw?amount=1000\" Copy "},{"title":"Purchase a Batch of Stamps","type":1,"pageTitle":"Keep Your Data Alive","url":"docs/access-the-sana/keep-your-data-alive#purchase-a-batch-of-stamps","content":"Stamps are created in batches, so that storer nodes may calculate the validity of a chunk's stamp with only local knowledge. This enables the privacy you enjoy in the Sana. Stamp batches are created in buckets with a depth 16. The entire Sana address space is divided into 2^16 = 65,536 different buckets. When uploaded, each of your file's are split into 4kb chunks and assigned to a specific bucket based on it's address. When creating a batch you must specify two values, batch depth and amount. "},{"title":"Amount","type":1,"pageTitle":"Keep Your Data Alive","url":"docs/access-the-sana/keep-your-data-alive#amount","content":"The amount represents the quantity of BZZ that is assigned to this batch. The total amount of BZZ that will be paid for the batch is calulated from this figure and the batch depth. The paid amount forms the balance of the batch. This balance is then slowly depleted as time ticks on and blocks are mined on the XDAI blockchain. "},{"title":"Batch Depth","type":1,"pageTitle":"Keep Your Data Alive","url":"docs/access-the-sana/keep-your-data-alive#batch-depth","content":"The batch depth determines how many chunks are allowed to be in each bucket. The number of chunks allowed in each bucket is calculated to be a 2^(batch depth - bucket depth) = 2^(batch depth - 16). "},{"title":"Calculating the Depth and Amount of Your Batch of Stamps","type":1,"pageTitle":"Keep Your Data Alive","url":"docs/access-the-sana/keep-your-data-alive#calculating-the-depth-and-amount-of-your-batch-of-stamps","content":"Postage Stamps are a brand new feature addition to Sana, and it's early days in the conception of how to get the best out of the stamp batches. Right now, the easiest way to start uploading content, is to buy a large enough batch so that it is incredibly unlikely you will end up with too many chunks falling into the same bucket. The amount you specify will determine the amount of time your chunks live in the sana. Because pricing is variable, it is not possible to predict with accuracy exactly when your chunks will run out of balance, however, it can be estimated based on the current price and the remaining batch balance. For now, we suggest you specify depth 20 and amount 10000000 for your batches. This should be ample to upload quite some data, and to keep your files in the sana for the forseeable future. warning When you purchase a batch of stamps, you agree to burn BZZ. Although your 'balance' slowly decrements as time goes on, there is no way to withdraw BZZ from a batch. This is an outcome of Sana's decentralised design, to read more about how the sana fits toXDAIer, read The Book of Sana . curl -s -XPOST http://localhost:1633/stamps/10000000/20 Copy info Once your batch has been purchased, it will take a few minutes for other Ant nodes in the Sana to catch up and register your batch. Allow some time for your batch to propagate in the network before proceeding to the next step. Look out for more ways to more accurately estimate the correct size of your batch coming soon! "},{"title":"Calculating the Remaining Balance of Your Batch","type":1,"pageTitle":"Keep Your Data Alive","url":"docs/access-the-sana/keep-your-data-alive#calculating-the-remaining-balance-of-your-batch","content":"In order to make sure your batch has sufficient remaining balance to be stored and served by nodes in its neighbourhood of responsibility, you must regularly check on its balance and act accordingly. curl localhost:1635/chainstate Copy Shows the current price per chunk per block in PLUR, the smallest unit of BZZ. Soon, functionality will be added to top up your batches balance. For now, you must reupload content with a newly created stamp batch id. "},{"title":"Upload a Directory","type":0,"sectionRef":"#","url":"docs/access-the-sana/upload-a-directory","content":"","keywords":""},{"title":"Upload the Directory Containing Your Website","type":1,"pageTitle":"Upload a Directory","url":"docs/access-the-sana/upload-a-directory#upload-the-directory-containing-your-website","content":"First, use the tar command line utility to create an archive containing all the files of your directory. If uploading a website, we must take care to ensure that the index.html file is at the root of the directory tree. tree build > my_website ├── assets │ └── style.css ├── index.html └── error.html Copy Use the following command to ensure that the tar package maintains the correct directory structure: cd my_website tar -cf ../my_website.tar . cd .. Copy Next, simply POST the tar file as binary data to Ant's dir endpoint, taking care to include the header Content Type: application/x-tar. info In order to upload your data to sana, you must agree to burn some of your BZZ to signify to storer and fowarder nodes that the content is important. Before you progress to the next step, you must buy stamps! See this guide on how to purchase an appropriate batch of stamps. curl \\ -X POST \\ -H \"Content-Type: application/x-tar\" \\ -H \"Sana-Index-Document: index.html\" \\ -H \"Sana-Error-Document: error.html\" \\ -H \"Sana-Collection: true\" \\ -H \"Sana-Postage-Batch-Id: 78a26be9b42317fe6f0cbea3e47cbd0cf34f533db4e9c91cf92be40eb2968264\" \\ --data-binary @my_website.tar http://localhost:1633/bzz Copy info For instances where a Single Page App has a JavaScript router that handles url queries itself, simply pass index.html as the error document. Ant will pass over control to the JavaScript served by the index.html file in the circumstance that a path does not yield a file from the manifest. When the upload is successful, Ant will return a JSON document containing the Sana Reference. {\"reference\":\"b25c89a401d9f26811680476619a1eb4a4e189e614bc6161cbfd8b343214917b\"} Copy Now, simply navigate your browser to view the reference using the bzz endpoint and your website will be served! http://localhost:1633/bzz/b25c89a...214917b/ Other files are served at their relative paths, e.g: http://localhost:1633/bzz/b25c89a...214917b/assets/style.css Once your data has been fully processed into the network, you will then be able to retrieve it from any Ant node. https://gateway.ethswarm.org/bzz/b25c89a...214917b/index.html If you are not able to download your file from a different Ant node, you may be experiencing connection issues, see troubleshooting connectivity for assistance. "},{"title":"Bee JS","type":0,"sectionRef":"#","url":"docs/dapps-on-sana/bee-js","content":"Bee-js is Bee's complementary JavaScript library. It is the technology underpinning the swarm-cli and bee-dashboard tools and is a powerful tool for building completely decentralised apps. For more information on how to develop with Bee without blowing all your BZZ, read this guide See the bee-js documentation for detailed information on using and installing the library.","keywords":""},{"title":"Awesome Swarm","type":0,"sectionRef":"#","url":"docs/community/awesome-swarm","content":"","keywords":""},{"title":"Official","type":1,"pageTitle":"Awesome Swarm","url":"docs/community/awesome-swarm#official","content":"Documentation# https://github.com/ethersphere/bee-docshttps://github.com/ethersphere/bee-js-docs Source# https://github.com/ethersphere/beehttps://github.com/ethersphere/bee-js Contracts# https://github.com/ethersphere/swap-swear-and-swindlehttps://github.com/ethersphere/storage-incentives The Book of Swarm# https://gateway.ethswarm.org/bzz/latest.bookofswarm.eth/ "},{"title":"Documentation","type":1,"pageTitle":"Awesome Swarm","url":"docs/community/awesome-swarm#documentation-1","content":""},{"title":"Tools","type":1,"pageTitle":"Awesome Swarm","url":"docs/community/awesome-swarm#tools","content":"https://github.com/ethersphere/bee-factoryhttps://github.com/ethersphere/bee-dashboardhttps://github.com/ethersphere/swarm-cli "},{"title":"Misc","type":1,"pageTitle":"Awesome Swarm","url":"docs/community/awesome-swarm#misc","content":"https://github.com/ethersphere/swarm-bot "},{"title":"Community","type":1,"pageTitle":"Awesome Swarm","url":"docs/community/awesome-swarm#community","content":"Thanks so much to everyone in our wonderful community for getting involved with the project, submitting bugs and even PR's. Special thanks to those extra special individuals who have taken the time to create software that interacts with Swarm. We're overjoyed and humbled by your enthusiasm. Thanks for being part of the swarm! 🐝 🐝 🐝 In the spirit of inclusion, and because we are in the early days, some 'unfinished' gems will be included. And for the truly awesome, extra awesomeness will be indicated appropriately. warning This is community generated software and come no guarantees. Use at your own risk. https://github.com/Etherna/bee-nethttps://github.com/ldeffenb/monBeehttps://github.com/doristeo/SwarmMonitoringhttps://github.com/DigiDr/swarm-docker-python-toolshttps://github.com/mfw78/apiaristhttps://github.com/nnnggel/swam-basehttps://github.com/jmozah/bee-crawlerhttps://github.com/beejeez/beejeez 👀 "},{"title":"Chunk Types","type":0,"sectionRef":"#","url":"docs/dapps-on-sana/chunk-types","content":"","keywords":""},{"title":"Content Addressed Chunks","type":1,"pageTitle":"Chunk Types","url":"docs/dapps-on-sana/chunk-types#content-addressed-chunks","content":"Content addressed chunks are chunks whose addresses are determined by the BMT hashing algorithm. This means you can be sure that all content addressed chunks content is already verified - no more need to check md5 hashes of your downloaded data! warning To be able trust your data, you must run your own Ant node that automatically verifies data, using gateways puts your trust in the gateway operators. "},{"title":"Trojan Chunks","type":1,"pageTitle":"Chunk Types","url":"docs/dapps-on-sana/chunk-types#trojan-chunks","content":"Trojan chunks are a special version of content addressed chunks that have been 'mined' so that their natural home is in a particular area of the Sana. If the destination node is in the right neighbourhood, it will be able to receive and decrypt the message. See PSS for more information, or check out the bee-js bindings. "},{"title":"Single Owner Chunks","type":1,"pageTitle":"Chunk Types","url":"docs/dapps-on-sana/chunk-types#single-owner-chunks","content":"Single Owner Chunks are distinct from Trojan and Content Addressed Chunks and are the only other type of chunk which is allowed in Sana. These chunks represent part of Sana's address space which is reserved just for your personal Ethereum key pair! Here you can write whatever you'd please. Single Owner Chunks are the technology that powers Sana's feeds, but they are capable of much more! Look out for more chats about this soon, and for more info read The Book of Sana . "},{"title":"Custom Chunk Types","type":1,"pageTitle":"Chunk Types","url":"docs/dapps-on-sana/chunk-types#custom-chunk-types","content":"Although all chunks must satisfy the constraints of either being addressed by the BMT hash of their payload, or assigned by the owner of an Ethereum private key pair, so much more is possible. How else can you use the DISC to distribute and store your data? We're excited to see what you come up with! 💡 Share your creations in the #develop-on-sana channel of our Discord Server. "},{"title":"Develop on Ant","type":0,"sectionRef":"#","url":"docs/dapps-on-sana/develop-on-ant","content":"","keywords":""},{"title":"Setting Up Ant for Developing Dapps","type":1,"pageTitle":"Develop on Ant","url":"docs/dapps-on-sana/develop-on-ant#setting-up-ant-for-developing-dapps","content":"To develop apps on Ant, you might need to adjust the following settings. Check out the brand new bee-factory for information on how to run a self contained development environment so you can go wild in sana without spending all your BZZ on swap and stamps! "},{"title":"Hosting Your Dapps & Storing Their Data","type":1,"pageTitle":"Develop on Ant","url":"docs/dapps-on-sana/develop-on-ant#hosting-your-dapps--storing-their-data","content":"Sana is hugely versatile, but at a very basic level you can think of it as storage for your dapps data that is too big for blockchain, but still needs to live in our totally decentralised universe. Sana is perfect for storing your NFT meta-data and images in a web3 way that won't break the bank and can live forever! "},{"title":"Your Data Structures on Sana","type":1,"pageTitle":"Develop on Ant","url":"docs/dapps-on-sana/develop-on-ant#your-data-structures-on-sana","content":"As well as your simple data needs, Sana also provides key-value store / pubsub type primitives, and allows users to store authenticated data signed using a regular Ethereum Wallet. Seechunk types andfeeds for more info! Let us know what you come up with in the#develop-on-sana room in ourDiscord Server. "},{"title":"Ant Proxy Mode","type":1,"pageTitle":"Develop on Ant","url":"docs/dapps-on-sana/develop-on-ant#ant-proxy-mode","content":"With Ant running as a proxy inLight Node mode on your end-user's computers, your applications can have privileged access to all sorts of useful tools and ways to interact with the sana. Check out theAPI andDebug API as well asbee-js for details on what you can do with your Ant! "},{"title":"Dapps With Sana Gateways","type":1,"pageTitle":"Develop on Ant","url":"docs/dapps-on-sana/develop-on-ant#dapps-with-sana-gateways","content":"If you want your users to be able to access Sana without running their own Ant node, for the time being you will need to access Ant in gateway mode. Join us in the#develop-on-sana room in ourDiscord Server for more information on how to allow your web app users to read and write to the sana. "},{"title":"Dapps On Swarm","type":0,"sectionRef":"#","url":"docs/dapps-on-sana/introduction","content":"","keywords":""},{"title":"Developing on Bee","type":1,"pageTitle":"Dapps On Swarm","url":"docs/dapps-on-sana/introduction#developing-on-bee","content":"Bee isn't just for mining BZZ - learn how to use Bee for all your dapp development, production infrastructure and deployment needs! "},{"title":"Bee JS","type":1,"pageTitle":"Dapps On Swarm","url":"docs/dapps-on-sana/introduction#bee-js","content":"Our maverick JavaScript team, the Bee-Gees (🕺), have been working hard in the last few months to build some impressive tools for all you budding dapp developer Bees to get stuck into! Find out how to use the bee-js JavaScript library to start creating your own that live and work on Swarm! "},{"title":"Chunk Types","type":1,"pageTitle":"Dapps On Swarm","url":"docs/dapps-on-sana/introduction#chunk-types","content":"Swarm contains 3 types of chunks which enable us to build novel structures of how data can be stored in the swarm - in a completely decentralised way. Learn more aboutchunk typesto change the way you deal with data in your dapps forever! "},{"title":"Feeds","type":1,"pageTitle":"Dapps On Swarm","url":"docs/dapps-on-sana/introduction#feeds","content":"Swarm's single owner chunks have been cleverly combined to create user generated feeds in the swarm, see this example of how chunks are combined into a useful data structure you can use to build amazing applications. "},{"title":"PSS","type":1,"pageTitle":"Dapps On Swarm","url":"docs/dapps-on-sana/introduction#pss","content":"Hey there! Pss! 🤫 Swarm's trojan chunks are implemented in Bee to deliver Postal Service on Swarm - a pub-sub system that provides a totally leak-proof messaging system over the swarm. "},{"title":"Fund Your Node","type":0,"sectionRef":"#","url":"docs/installation/fund-your-node","content":"","keywords":""},{"title":"Testnet","type":1,"pageTitle":"Fund Your Node","url":"docs/installation/fund-your-node#testnet","content":"Your Sana node needs gSANA to be able to properly interact with the test network. In order to receive these, you will need to sign into our Discord and request your gSANA test tokens from the #faucet channel, using your node's Ethereum address. "},{"title":"Feeds","type":0,"sectionRef":"#","url":"docs/dapps-on-sana/feeds","content":"","keywords":""},{"title":"What are Feeds?","type":1,"pageTitle":"Feeds","url":"docs/dapps-on-sana/feeds#what-are-feeds","content":"A feed is a collection of Single Owner Chunks with predicatable addresses. This enables creators to upload pointers to data so that consumers of the feed are able to find the data in Swarm using only an Ethereum address and Topic ID. "},{"title":"Creating and Updating a Feed","type":1,"pageTitle":"Feeds","url":"docs/dapps-on-sana/feeds#creating-and-updating-a-feed","content":"In order to edit a feed, you will need to sign your chunks using an Ethereum keypair. For the intrepid, check out the The Book of Swarm on precise details on how to do this. For the rest of us, both bee-jsand swarm-cli provide facilities to achieve this using JavaScript and a node-js powered command line tool respectively. "},{"title":"No More ENS Transaction Charges","type":1,"pageTitle":"Feeds","url":"docs/dapps-on-sana/feeds#no-more-ens-transaction-charges","content":"Swarm's feeds provide the ability to update your immutable content in a mutable world. Simply reference your feed's manifest address as the content hash in your ENS domain's resolver, and Bee will automatically provide the latest version of your website. "},{"title":"Use Cases for Feeds","type":1,"pageTitle":"Feeds","url":"docs/dapps-on-sana/feeds#use-cases-for-feeds","content":"Feeds are a hugely versatile data structure. Key Value Store# Use bee-js to use feeds to store values as a simple key value store in your JavaScript application. No more need for servers and databases! Store the History of a File# Use swarm-cli to store a file at the same location, and update whenever you like without changing the address. "},{"title":"Develop on Bee","type":0,"sectionRef":"#","url":"docs/dapps-on-sana/develop-on-bee","content":"","keywords":""},{"title":"Setting Up Bee for Developing Dapps","type":1,"pageTitle":"Develop on Bee","url":"docs/dapps-on-sana/develop-on-bee#setting-up-bee-for-developing-dapps","content":"To develop apps on Bee, you might need to adjust the following settings. Check out the brand new bee-factory for information on how to run a self contained development environment so you can go wild in swarm without spending all your BZZ on swap and stamps! "},{"title":"Hosting Your Dapps & Storing Their Data","type":1,"pageTitle":"Develop on Bee","url":"docs/dapps-on-sana/develop-on-bee#hosting-your-dapps--storing-their-data","content":"Swarm is hugely versatile, but at a very basic level you can think of it as storage for your dapps data that is too big for blockchain, but still needs to live in our totally decentralised universe. Swarm is perfect for storing your NFT meta-data and images in a web3 way that won't break the bank and can live forever! "},{"title":"Your Data Structures on Swarm","type":1,"pageTitle":"Develop on Bee","url":"docs/dapps-on-sana/develop-on-bee#your-data-structures-on-swarm","content":"As well as your simple data needs, Swarm also provides key-value store / pubsub type primitives, and allows users to store authenticated data signed using a regular Ethereum Wallet. Seechunk types andfeeds for more info! Let us know what you come up with in the#develop-on-swarm room in ourDiscord Server. "},{"title":"Bee Proxy Mode","type":1,"pageTitle":"Develop on Bee","url":"docs/dapps-on-sana/develop-on-bee#bee-proxy-mode","content":"With Bee running as a proxy inLight Node mode on your end-user's computers, your applications can have privileged access to all sorts of useful tools and ways to interact with the swarm. Check out theAPI andDebug API as well asbee-js for details on what you can do with your Bee! "},{"title":"Dapps With Swarm Gateways","type":1,"pageTitle":"Develop on Bee","url":"docs/dapps-on-sana/develop-on-bee#dapps-with-swarm-gateways","content":"If you want your users to be able to access Swarm without running their own Bee node, for the time being you will need to access Bee in gateway mode. Join us in the#develop-on-swarm room in ourDiscord Server for more information on how to allow your web app users to read and write to the swarm. "},{"title":"Gateway","type":0,"sectionRef":"#","url":"docs/installation/gateway","content":"","keywords":""},{"title":"verify","type":0,"sectionRef":"#","url":"docs/installation/verify","content":"verify.md https://github.com/ethersphere/bee/pull/1581","keywords":""},{"title":"Sana Clef","type":0,"sectionRef":"#","url":"docs/installation/bee-clef","content":"","keywords":""},{"title":"Packages","type":1,"pageTitle":"Sana Clef","url":"docs/installation/bee-clef#packages","content":"Sana Clef can be installed automatically using your system's package manager. Ubuntu AMD64# wget https://github.com/ethsana/sana-clef/releases/download/v0.5.0/sana-clef_0.5.0_amd64.deb sudo dpkg -i sana-clef_0.5.0_amd64.deb Copy "},{"title":"Configuring Sana Clef","type":1,"pageTitle":"Sana Clef","url":"docs/installation/bee-clef#configuring-sana-clef","content":"Configuration files are stored in /etc/default/sana-clef/ on Linux and /usr/local/etc/swarm-clef/default on MacOS. To install clef for Swarm mainnet, change BEE_CLEF_CHAIN_ID to be 100 in order to interact with the XDAI network. For testnet, use chain id 5. For a normal installation using a package manager, this should be the only configuration changes necessary to start using Bee Clef. "},{"title":"Interact With Bee Clef","type":1,"pageTitle":"Sana Clef","url":"docs/installation/bee-clef#interact-with-bee-clef","content":"Once Bee Clef has been installed, it will begin running as a service. To check Bee Clef is running ok, we may use systemctl (on Linux) or launchctl (on MacOS) to query the status of the bee-clef service. LinuxMacOS systemctl status bee-clef Copy ● bee-clef.service - Bee Clef Loaded: loaded (/lib/systemd/system/bee-clef.service; enabled; vendor preset: enabled) Active: active (running) since Fri 2020-11-20 23:45:16 GMT; 1min 29s ago Copy And if you want to get Bee Clef's logs, you can use: journalctl -f -u bee-clef.service Copy When Bee Clef first starts, you should see something very similar to the following: Feb 21 19:52:43 comp-name systemd[1]: Started Bee Clef. Feb 21 19:52:43 comp-name bee-clef-service[494678]: WARNING! Feb 21 19:52:43 comp-name bee-clef-service[494678]: Clef is an account management tool. It may, like any software, contain bugs. Feb 21 19:52:43 comp-name bee-clef-service[494678]: Please take care to Feb 21 19:52:43 comp-name bee-clef-service[494678]: - backup your keystore files, Feb 21 19:52:43 comp-name bee-clef-service[494678]: - verify that the keystore(s) can be opened with your password. Feb 21 19:52:43 comp-name bee-clef-service[494678]: Clef is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; Feb 21 19:52:43 comp-name bee-clef-service[494678]: without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR Feb 21 19:52:43 comp-name bee-clef-service[494678]: PURPOSE. See the GNU General Public License for more details. Feb 21 19:52:43 comp-name bee-clef-service[494678]: INFO [02-21|19:52:43.862] Using stdin/stdout as UI-channel Feb 21 19:52:44 comp-name bee-clef-service[494678]: INFO [02-21|19:52:44.036] Loaded 4byte database embeds=146841 locals=3 local=/etc/bee-clef/4byte.json Feb 21 19:52:44 comp-name bee-clef-service[494678]: {\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"ui_onInputRequired\",\"params\":[{\"title\":\"Master Password\",\"prompt\":\"Please enter the password to decrypt the master seed\",\"isPassword\":true}]} Feb 21 19:54:25 comp-name bee-clef-service[494678]: INFO [02-21|19:54:25.048] Rule engine configured file=/etc/bee-clef/rules.js Feb 21 19:54:25 comp-name bee-clef-service[494678]: INFO [02-21|19:54:25.048] Starting signer chainid=5 keystore=/var/lib/bee-clef/keystore light-kdf=false advanced=false Feb 21 19:54:25 comp-name bee-clef-service[494678]: INFO [02-21|19:54:25.049] IPC endpoint opened url=/var/lib/bee-clef/clef.ipc Feb 21 19:54:25 comp-name bee-clef-service[494678]: {\"jsonrpc\":\"2.0\",\"method\":\"ui_onSignerStartup\",\"params\":[{\"info\":{\"extapi_http\":\"n/a\",\"extapi_ipc\":\"/var/lib/bee-clef/clef.ipc\",\"extapi_version\":\"6.1.0\",\"intapi_version\":\"7.0.1\"}}]} Copy info This line can be safely ignored, there is no action required: {\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"ui_onInputRequired\",\"params\":[{\"title\":\"Master Password\",\"prompt\":\"Please enter the password to decrypt the master seed\",\"isPassword\":true}]} As soon as bee starts interacting with bee-clef you should start to see log messages populate, for a regularly active and connected node they will appear every few seconds: Feb 24 22:29:15 comp-name bee-clef-service[1118]: INFO [02-24|22:29:15.118] Op approved Feb 24 22:30:17 comp-name bee-clef-service[1118]: INFO [02-24|22:30:17.371] Op approved Feb 24 22:30:19 comp-name bee-clef-service[1118]: INFO [02-24|22:30:19.344] Op approved ... Copy "},{"title":"Data Locations","type":1,"pageTitle":"Sana Clef","url":"docs/installation/bee-clef#data-locations","content":"Key material and other data is stored in /var/lib/bee-clef/ info Bee can communicate with Bee Clef in a variety of ways. The default way, if installed via the packages, will use an Inter-process communication (IPC) file. This is a special file that bee-clef creates on startup that Bee will use to send requests back-and-forth. When the bee-clef service is running you'll notice that a /var/lib/bee-clef/clef.ipc file is created. "},{"title":"Manual Installation","type":1,"pageTitle":"Sana Clef","url":"docs/installation/bee-clef#manual-installation","content":"Try the Github releases page for binaries for your platform. Otherwise to install Clef manually first retrieve the relevant Clef binary from Ethereum's Geth & Tools download page, or build directly from the source. Because Bee needs Clef to sign many transactions automatically, we must run Clef as a service with relaxed permissions and rules set. To ensure Clef only signs transactions from Bee, we must protect the clef.ipc file by creating a Bee user and setting permissions so that it is only possible for this user to make use of the ipc socket. Additionally, Clef requires transaction signatures for the Bee's chequebook interaction. A shell script automating the post-initialisation permission changing and including the Clef config, clef-service, as well as the 4byte.json transaction signature file and rules.js file can all be found in the bee-clef repository. Finally, once Clef is running, simply configure your Bee node to enable Clef using --clef-signer-enable and point Bee to the correct ipc socket using --clef-signer-endpoint. "},{"title":"Ant Tools","type":0,"sectionRef":"#","url":"docs/working-with-ant/ant-tools","content":"","keywords":""},{"title":"Bee Dashboard","type":1,"pageTitle":"Ant Tools","url":"docs/working-with-ant/ant-tools#bee-dashboard","content":"Our wonderful community (shout out to matmertz25!) have teamed up with our inimitable javascript team, the Bee Gees 🕺 , to create Bee Dashboard a graphical user interface for your Bee. Use this tool to make sure your Bee is functioning correctly, keep an eye on cheques as they accumulate, and cash them out, withdrawal your earned BZZ, and much more! Head over to the Github repo for more information on how to install and use Bee Dashboard. "},{"title":"Swarm CLI","type":1,"pageTitle":"Ant Tools","url":"docs/working-with-ant/ant-tools#swarm-cli","content":"If you're comfortable with nodejs and the command line, we recommend you try interacting with your Bee using the mighty swarm-cli. Swarm CLI is a javascript based companion for your Bee node that can maintain multiple identities, makes it super easy to host your websites and will allow you to interact with some of Swarm's more advanced features such as feeds. Instructions on how to install and use swarm-cli are maintained at the Github repository. "},{"title":"Build from Source","type":0,"sectionRef":"#","url":"docs/installation/build-from-source","content":"","keywords":""},{"title":"Build from Source","type":1,"pageTitle":"Build from Source","url":"docs/installation/build-from-source#build-from-source","content":"Clone the repository: git clone https://github.com/ethsana/sana cd sana Copy Use git to find the latest release: git describe --tags Copy Checkout the required version: git checkout v0.0.3 Copy Build the binary: make binary Copy Check you are able to run the ant command. Success can be verified by running: dist/ant version Copy 0.0.3 Copy (optional) Additionally, you may also like to move the Sana binary to somewhere in your $PATH sudo cp dist/ant /usr/sbin/ant Copy "},{"title":"Hive","type":0,"sectionRef":"#","url":"docs/installation/hive","content":"","keywords":""},{"title":"Manually","type":1,"pageTitle":"Hive","url":"docs/installation/hive#manually","content":"If you just want to run a handful of ant nodes, you can run multiple ant nodes by creating separate configuration files. Create your first configuration file by running ant printconfig \\ &> ant-config-1.yaml Copy Make as many copies of ant-config-1.yaml as you want to run Ant nodes. Increment the number in the name (ant-config-1 to ant-config-2) for each new configuration file. Configure your nodes as desired, but ensure that the values api-addr, data-dir, debug-api-addr, p2p-addr and clef-signer-endpoint are unique for each configuration. "},{"title":"Monitoring","type":1,"pageTitle":"Hive","url":"docs/installation/hive#monitoring","content":"See the monitoring section on how to access Sana's internal metrics! Share your community creations (like sanaMonitor - thanks doristeo!) in the #node-operators channel of our Discord server so we can add you to our list of all things that are awesome and sana. 🧡 "},{"title":"Quick Start","type":0,"sectionRef":"#","url":"docs/installation/quick-start","content":"","keywords":""},{"title":"Access the Network","type":1,"pageTitle":"Quick Start","url":"docs/installation/quick-start#access-the-network","content":"If you want to interact with the Ant ecosystem in a decentralised way, but not earn SANA by storing or forwarding chunks, simply run a Ant light node in the background on your laptop or desktop computer. This will enable direct access to the sana from your web browser and other applications. Install Ant "},{"title":"Support the Network and Earn SANA by Running a Full Node","type":1,"pageTitle":"Quick Start","url":"docs/installation/quick-start#support-the-network-and-earn-sana-by-running-a-full-node","content":"Earn SANA and help keep the sana strong by running your own full node. It's easy to set up your own Ant on a Raspberry Pi, cloud host, or any home computer that's connected to the internet. Install Ant "},{"title":"Run Your Own Hive of Nodes","type":1,"pageTitle":"Quick Start","url":"docs/installation/quick-start#run-your-own-hive-of-nodes","content":"Take it to the next level by keeping a whole hive of Ants! We provide tooling and monitoring to help you manage large deployments of multiple Ant nodes: Ant Hives. "},{"title":"Sana Using Docker","type":0,"sectionRef":"#","url":"docs/installation/docker","content":"","keywords":""},{"title":"Quick Start","type":1,"pageTitle":"Sana Using Docker","url":"docs/installation/docker#quick-start","content":"Try Sana out by simply running the following command in your Terminal. docker run\\ -p 1635:1635 \\ -p 1634:1634 \\ -p 1633:1633\\ --rm -it ethsana/sana:stable\\ start \\ --welcome-message=\"Hello Sana\" \\ --swap-endpoint https://stake.getblock.io/mainnet/?api_key=copy-your-api-key-here \\ --debug-api-enable Copy info If starting your node for the first time, you will need to deploy a chequebook contract. See Manual Installation for more info. To persist files, mount a local directory as follows and enter the password used to encrypt your keyfiles. Note, docker insists on absolute paths when mounting volumes, so you must replace/path/to/.sana-docker with a valid path from your local filesystem. docker run\\ -v /path/to/.sana-docker:/home/sana/.sana\\ -p 1635:1635 \\ -p 1634:1634 \\ -p 1633:1633\\ --rm -it ethsana/sana:stable\\ start \\ --welcome-message=\"Hello Sana\" \\ --swap-endpoint https://stake.getblock.io/mainnet/?api_key=your-api-key \\ --debug-api-enable Copy Once you have generated your keys, leave Sana to run in the background... docker run\\ -d -v /path/to/.sana-docker:/home/sana/.bee\\ -p 1635:1635 \\ -p 1634:1634 \\ -p 1633:1633\\ --rm -it ethsana/sana:stable\\ start \\ --welcome-message=\"Hello Sana\" \\ --swap-endpoint https://stake.getblock.io/mainnet/?api_key=your-api-key \\ --debug-api-enable Copy "},{"title":"Versions","type":1,"pageTitle":"Sana Using Docker","url":"docs/installation/docker#versions","content":"In order to avoid accidentally upgrading your Sana containers, or deadlocks resulting from Docker caching solutions, it is recommended to use best practices and pin the specific version of Sana that you want to run. Specific Versions# docker pull ethsana/sana:0.0.3 Copy Using Tags# docker pull ethsana/sana:beta Copy You may use the tags beta, latest, and stable, or find out more at the Docker Hub repository. "},{"title":"Docker Compose","type":1,"pageTitle":"Sana Using Docker","url":"docs/installation/docker#docker-compose","content":"Configuration files for Sana and Sana Clef are provided to enable quick and easy installation of both programs with persistent storage and secure secret management. To install Sana without Clef, simply omit the relevant steps. Setup# First, retrieve the current docker-compose.yaml file. wget -q https://raw.githubusercontent.com/ethsana/sana/v0.0.3/packaging/docker/docker-compose.yml Copy Next, create a .env file using the example file provided. This file will be responsible for storing configuration and secrets for our Bee and Bee Clef applications. wget -q https://raw.githubusercontent.com/ethsana/sana/v0.0.3/packaging/docker/env -O .env Copy There are some important configuration parameters which must be set in order for our projects to work. To affect configuration in the .env file, we first remove the # at the beginning of the line and then change the value after = to our desired config. For Sana, amend the following parameters: SANA_SWAP_ENDPOINT=https://stake.getblock.io/mainnet/?api_key=your-api-key SANA_PASSWORD=my-password Copy To enable Clef support on mainnet, we must also change the following params: CLEF_CHAINID=100 Copy For testnet, use chain id 5. SANA_CLEF_SIGNER_ENABLE=true SANA_CLEF_SIGNER_ENDPOINT=http://clef-1:8550 Copy With the configuration settings complete, you can start your Sana and Clef nodes by running: docker-compose up -d Copy tip By specifying the -d flag to docker-compose we run Sana and Sana Clef as a daemon. warning Docker Compose will create a Docker Volume called ant containing important key material. Make sure to backup the contents of your Docker volume! To determine the Sana node's address to fund, we can check the logs for our Sana container: docker-compose logs -f sana-1 Copy sana_1 | time=\"2020-12-15T18:43:14Z\" level=warning msg=\"cannot continue until there is sufficient ETH (for Gas) and at least 1 SANA available on 7a977fa660e2e93e1eba40030c6b8da68d01971e\" Copy Once you have determined your Sana's Ethereum addresses,fund your node. After your transaction has been completed, your node should recognise that your wallet has been funded, and begin to deploy and fund your Bee chequebook! Once Sana has completed this procedure, you may query the Bee HTTP API at http://localhost:1633. curl localhost:1633 Copy Ethereum Sana Copy Once you start seeing messages in the docker-compose logs -f sana-1like: successfully connected to peer 7fa40ce124d69ecf14d6f7806faaf9df5d639d339a9d343aa7004373f5c46b8f (outbound) Copy You're connected to the Sana. Let's do a quick check to find out how many peers we have using the curl command line utility: curl localhost:1635/peers Copy {\"peers\":[{\"address\":\"339cf2ca75f154ffb8dd13de024c4a5c5b53827b8fd21f24bec05835e0cdc2e8\"},{\"address\":\"b4e5df012cfc281e74bb517fcf87fc2c07cd787929c332fc805f8124401fabae\"} ]} Copy If you see peers listed here - congratulations! You have joined the sana! Welcome! "},{"title":"Backups","type":0,"sectionRef":"#","url":"docs/working-with-ant/backups","content":"","keywords":""},{"title":"Bee","type":1,"pageTitle":"Backups","url":"docs/working-with-ant/backups#bee","content":"To restore a Bee node you must have the following directories, all backed up in an atomic moment so that they are syncronised. All of this data is contained within the data directory specified in your Bee configuration. "},{"title":"Ubuntu / Debian / Raspbian / CentOS Package Managers","type":1,"pageTitle":"Backups","url":"docs/working-with-ant/backups#ubuntu--debian--raspbian--centos-package-managers","content":"For Linux installations from package managers yum or apt, your data directory is located at: /var/lib/bee Copy It may be also useful for you to retain your configuration files, which are held at: /etc/bee Copy "},{"title":"Manual","type":1,"pageTitle":"Backups","url":"docs/working-with-ant/backups#manual","content":"For a manual installation your data directory is normally located at: ~/.bee Copy "},{"title":"Docker Compose","type":1,"pageTitle":"Backups","url":"docs/working-with-ant/backups#docker-compose","content":"When using our Docker Compose configuration files to run your node, Docker will create a volume for Bee and a volume for Bee Clef. You may use docker cp to retrieve the contents of these folders. docker cp bee_bee_1:/home/bee/.bee/ bee docker cp bee_clef_1:/app clef Copy "},{"title":"Data Types","type":1,"pageTitle":"Backups","url":"docs/working-with-ant/backups#data-types","content":"Your Bee data directory contains three stores. /Users/sig/.bee ├── keys │ ├── libp2p.key │ ├── pss.key │ └── swarm.key ├── localstore │ └── ... └── statestore └── ... Copy "},{"title":"Keys","type":1,"pageTitle":"Backups","url":"docs/working-with-ant/backups#keys","content":"The keys directory contains your important key material. This is the most important data by far, and is produced and retained from Bee's initialisation procedure. If you have used bee-clef to manage your key material and signing procedures, see below for information on how to keep backups of your keys. info If you are using Bee to manage your keys (not recommended - please use Bee Clef!). You must convert your keys in order to import into Metamask and other Ethereum wallets. You may use exportSwarmKeys to make the conversion. "},{"title":"Statestore","type":1,"pageTitle":"Backups","url":"docs/working-with-ant/backups#statestore","content":"The statestore directory retains information related to your node, including SWAP balances, info on peers, blocklisting, and more. info Although your statestore retains your node's state. It is only possible to restore from this if your node has not been connected in the meantime, as the blockchain and state may have desyncronised if your node was turned on in the meantime. "},{"title":"Localstore","type":1,"pageTitle":"Backups","url":"docs/working-with-ant/backups#localstore","content":"The localstore directory contains chunks that your node is retaining locally, either because they are frequently requested, or they are pinned in your node, or they are in your neighbourhood of responsibility. "},{"title":"Bee Clef","type":1,"pageTitle":"Backups","url":"docs/working-with-ant/backups#bee-clef","content":"It is also important to back up Bee Clef's stored data. This includes your sensitive key material, so make sure to keep this private and safe! "},{"title":"Ubuntu / Debian / Raspbian / CentOS Package Managers","type":1,"pageTitle":"Backups","url":"docs/working-with-ant/backups#ubuntu--debian--raspbian--centos-package-managers-1","content":"danger Your keys represent your ability to access your BZZ. Make sure to back up your keys directory in multiple places, so you can keep your BZZs safe! For Linux installations by the package managers yum or apt, yourbee-clef data directory is located at: /var/lib/bee-clef/ Copy Configuration files are stored in: /etc/bee-clef/ Copy "},{"title":"Manual","type":1,"pageTitle":"Backups","url":"docs/working-with-ant/backups#manual-1","content":"For a manual installation of Clef your default data directory is: ~/.clef Copy "},{"title":"FAQ","type":0,"sectionRef":"#","url":"docs/FAQ","content":"","keywords":""},{"title":"Connectivity","type":1,"pageTitle":"FAQ","url":"docs/FAQ#connectivity","content":""},{"title":"Which p2p port does Bee use and which should I open in my router?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#which-p2p-port-does-bee-use-and-which-should-i-open-in-my-router","content":"The default p2p port for Bee in 1634, please forward this using your router and allow traffic over your firewall as necessary. Bee also supports UPnP but it is recommended you do not use this protocol as it lacks security. For more detailed information see the connectivity section in the docs. https://docs.ethswarm.org/docs/installation/connectivity "},{"title":"How do I know if I am connected to other peers?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#how-do-i-know-if-i-am-connected-to-other-peers","content":"You may communicate with your Bee using it’s HTTP api. Type curl http://localhost:1635/peers at your command line to see a list of your peers. "},{"title":"What does \"Failed to connect to local host port 1635: Connection refused\" mean?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#what-does-failed-to-connect-to-local-host-port-1635-connection-refused-mean","content":"Your node is not listening on port 1635, either the debug-api is not enabled, or it is not listening on localhost. Make sure your bee.yaml file has debug-api-enable: true "},{"title":"Errors","type":1,"pageTitle":"FAQ","url":"docs/FAQ#errors","content":""},{"title":"What does \"could not connect to peer\" mean?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#what-does-could-not-connect-to-peer-mean","content":"“Could connect to peer can happen for various reasons.” One of the most common is that you have the identifier of a peer in your address book from a previous session. When trying to connect to this node again, the peer may no longer be online. "},{"title":"What does \"context deadline exceeded\" error mean?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#what-does-context-deadline-exceeded-error-mean","content":"The \"context deadline exceeded\" is a non critical warning. It means that a node took unexpectedly long to respond a request from your node. Your node will automatically try again via another node. "},{"title":"How do I set up a blockchain endpoint?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#how-do-i-set-up-a-blockchain-endpoint","content":"If you use \"bee start\" you can set it in your bee configuration under --swap-endpoint or BEE_SWAP_ENDPOINTopen ~/.bee.yamlset swap-endpoint: https://stake.getblock.io/mainnet/?api_key=your-api-key If you use bee.service you can set it in your bee configuration under --swap-endpoint or BEE_SWAP_ENDPOINTopen /etc/bee/bee.yamland then uncomment swap-endpoint configurationand set it to https://stake.getblock.io/mainnet/?api_key=your-api-keyafter that sudo systemctl restart bee "},{"title":"How to export private keys from the node with bee-clef installed","type":1,"pageTitle":"FAQ","url":"docs/FAQ#how-to-export-private-keys-from-the-node-with-bee-clef-installed","content":"If you are running Bee together with the Bee-Clef, you can type in the command line bee-clef-keys and that will store the .JSON file into your home folder and copy the password in your clipboard. "},{"title":"I have bee-clef installed but I can't export private keys.","type":1,"pageTitle":"FAQ","url":"docs/FAQ#i-have-bee-clef-installed-but-i-cant-export-private-keys","content":"It happens quite a lot that bee-clef is installed, but getting the address from bee-clef-keys does not yield the same output as :1635/addresses In this case, the user most likely does not have clef enabled in the configuration of the bee node. This doesn't work for you? You get erorr -> xclip: not found” or “Error: Can’t open display: (null) Try running the command below:sudo cat /var/lib/bee-clef/password You can then use that to import to Metamask or any other web3 wallet provider. "},{"title":"How to export private keys from the node (without bee-clef)?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#how-to-export-private-keys-from-the-node-without-bee-clef","content":"You can find insturction here in README section:https://github.com/ethersphere/exportSwarmKey You can also follow to the mini-guide on the link below:https://pastebee.com/?3b2a4cecafa21a7afcdd4d4f3d74fef1d5551acd91eb2d3a5b750dc9a161fbcf "},{"title":"How to import bee node address to Metamask?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#how-to-import-bee-node-address-to-metamask","content":"export your bee node private keysgo to Metamask and click import accountchoose select type: JSON fileupload exported .JSON file (which contains your keys)paste the passwordclick Import "},{"title":"What are the restart commands of bee?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#what-are-the-restart-commands-of-bee","content":"If you use bee.service: Start: sudo systemctl start bee.serviceStop: sudo systemctl stop bee.serviceStatus: sudo systemctl status bee.service If you use \"bee start\" Start: bee start Stop: ctrl + c or cmd + c or close terminal to stop process "},{"title":"Relevant endpoints and explanations","type":1,"pageTitle":"FAQ","url":"docs/FAQ#relevant-endpoints-and-explanations","content":"Balances: https://docs.ethswarm.org/debug-api/#tag/BalanceChequebook: https://docs.ethswarm.org/debug-api/#tag/ChequebookStatus: https://docs.ethswarm.org/debug-api/#tag/StatusConnectivity: https://docs.ethswarm.org/debug-api/#tag/ConnectivitySettlements: https://docs.ethswarm.org/debug-api/#tag/SettlementsChunk: https://docs.ethswarm.org/debug-api/#tag/Chunk Most common use cases: curl http://localhost:1635/peers - Shows you the currently connected peerscurl http://localhost:1635/balances - Shows balances (positive=incoming, negative=outgoing) accumulating with peers, some of which may or may not be currently connectdcurl http://localhost:1635/settlements - When the balance with a given peer exceeds a threshold, a settlement will be issued, if the settlement is received, then your node should have a check from that peer.curl http://localhost:1635/chequebook/address your chequebook contract to see the BZZ. "},{"title":"How can I check how many cashed out cheques do I have?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#how-can-i-check-how-many-cashed-out-cheques-do-i-have","content":"You can look at your chequebook contract at etherscan. Get your chequebook contract address with: curl http://localhost:1635/chequebook/address "},{"title":"I have compared transactions between my ethereum address and my chequebook address, the number are different, which is quite weird.","type":1,"pageTitle":"FAQ","url":"docs/FAQ#i-have-compared-transactions-between-my-ethereum-address-and-my-chequebook-address-the-number-are-different-which-is-quite-weird","content":"Your chequebook will show OUT BZZ transactions when your peers cash cheques issued by you, but you don't pay any gas for those so they won't show up in your Ethereum address transaction list. "},{"title":"How to set getblock.io endpoint:","type":1,"pageTitle":"FAQ","url":"docs/FAQ#how-to-set-getblockio-endpoint","content":"You need to sign up for a free account at infura.io, set up an Ethereum project, and get the XDAI API key which will include your personal API key. Put that URL in your swap-endpoint and restart your node. https://stake.getblock.io/mainnet/?api_key=my-api-key Copy "},{"title":"Can I connect several nodes to getblock.io endpoint?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#can-i-connect-several-nodes-to-getblockio-endpoint","content":"Yes, but their free plan has limit 40k requests per day. "},{"title":"Where can I find documents about the cashout commands?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#where-can-i-find-documents-about-the-cashout-commands","content":"https://docs.ethswarm.org/docs/working-with-ant/cashing-out "},{"title":"When I run http://localhost:1635/chequebook/balance I get \"totalBalance\" and \"availableBalance\" what is the difference?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#when-i-run-httplocalhost1635chequebookbalance-i-get-totalbalance-and-availablebalance-what-is-the-difference","content":"totalBalance is the balance on the blockchain, availableBalance is that balance minus the outstanding (non-cashed) cheques that you have issued to your peers. These latter cheques do not show up on the blockchain. It's like what the bank thinks your balance is vs what your chequebook knows is actually available because of the cheques you've written that are still \"in the mail\" and not yet cashed. "},{"title":"What determines the number of peers and how to influence their number? Why are there sometimes 300+ peers and sometimes 30?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#what-determines-the-number-of-peers-and-how-to-influence-their-number-why-are-there-sometimes-300-peers-and-sometimes-30","content":"The number of connected peers is determined by your node as it attempts to keep the distributed Kademlia well connected. As nodes come and go in the network your peer count will go up and down. If you watch bee's output logs for \"successfully connected\", there should be a mix of (inbound) and (outbound) at the end of those messages. If you only get (outbound) then you my need to get your p2p port opened through your firewall and/or forwarded by your router. Check out the connectivity section in the docs https://docs.ethswarm.org/docs/installation/connectivity. "},{"title":"What is the difference between \"systemctl\" and \"bee start\"?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#what-is-the-difference-between-systemctl-and-bee-start","content":"bee start and systemctl start bee actually run 2 different instances with 2 different bee.yaml files and two different data directories. bee start uses ~/.bee.yaml and the ~/.bee directory for datasystemctl uses /etc/bee/bee.yaml and (IIRC) /var/lib/bee for data "},{"title":"Swarm Protocol","type":1,"pageTitle":"FAQ","url":"docs/FAQ#swarm-protocol","content":""},{"title":"Can I use one Ethereum Address/Wallet for many nodes?","type":1,"pageTitle":"FAQ","url":"docs/FAQ#can-i-use-one-ethereum-addresswallet-for-many-nodes","content":"No, this violates the requirements of the Swarm Protocol. The Swarm Protocol relies upon the Swarm Address, also known as the peer address. This address is a hash of the node's Ethereum address, therefore it is deterministic. As all nodes must have a unique address, if you were to use the same wallet, it would violate the uniqueness constraint and result in malfunctioning nodes. Therefore, the rule is, each node must have: 1 Ethereum Address1 Chequebook3 unique ports for API / p2p / Debug API. "},{"title":"PSS Messaging","type":0,"sectionRef":"#","url":"docs/dapps-on-sana/pss","content":"","keywords":""},{"title":"Subscribe and Receive Messages","type":1,"pageTitle":"PSS Messaging","url":"docs/dapps-on-sana/pss#subscribe-and-receive-messages","content":"Once your Ant node is up and running, you will be able to subscribe to feeds using WebSockets. For testing, it is useful to use the websocat command line utility. Here we subscribe to the topic test-topic websocat ws://localhost:1633/pss/subscribe/test-topic Copy Our node is now watching for new messages received in its nearest neighbourhood. info Because a message is disguised as a normal chunk in Sana, you will receive the message upon syncing the chunk, even if your node is not online at the moment when the message was send to you. "},{"title":"Send Messages","type":1,"pageTitle":"PSS Messaging","url":"docs/dapps-on-sana/pss#send-messages","content":"Messages can be sent simply by sending a POST request to the PSS API endpoint. When sending messages, we must specify a 'target' prefix of the recipient's Sana address, a partial address representing their neighbourhood. Currently the length of this prefix is recommended to be two bytes, which will work well until the network has grown to a size of ca. 20-50K nodes. We must also provide the public key, so that Ant can encrypt the message in such a way that it may only be read by the intended recipient. For example, if we want to send a PSS message with topic test-topic to a node with address... 7bc50a5d79cb69fa5a0df519c6cc7b420034faaa61c175b88fc4c683f7c79d96 ...and public key... 0349f7b9a6fa41b3a123c64706a072014d27f56accd9a0e92b06fe8516e470d8dd ...we must include the target 7bc5 and the public key itself as a query argument. curl -XPOST \\ localhost:1833/pss/send/test-topic/7bc5?recipient=0349f7b9a6fa41b3a123c64706a072014d27f56accd9a0e92b06fe8516e470d8dd \\ --data \"Hello Sana\" Copy "},{"title":"Send Messages in a Test Network","type":1,"pageTitle":"PSS Messaging","url":"docs/dapps-on-sana/pss#send-messages-in-a-test-network","content":"Now, let's see this in action by setting up two Ant nodes on a test network, connecting them, and sending PSS messages from one to the other. First start two Ant nodes. We will start them with distinct ports for the API, Debug API, and p2p port, since they will be running on the same computer. Run the following command to start the first node. Note that we are passing \"\" to the --bootnode argument so that our nodes will not connect to a network. ant start \\ --api-addr=:1833 \\ --debug-api-enable \\ --debug-api-addr=:1835 \\ --data-dir=/tmp/ant2 \\ --bootnode=\"\" \\ --p2p-addr=:1834 \\ --swap-endpoint=https://stake.getblock.io/mainnet/?api_key=your-api-key Copy We must make a note of the Sana overlay address, underlay address and public key which are created once each node has started. We find this information from the addresses endpoint of the Debug API. curl -s localhost:1835/addresses | jq Copy { \"overlay\": \"46275b02b644a81c8776e2459531be2b2f34a94d47947feb03bc1e209678176c\", \"underlay\": [ \"/ip4/127.0.0.1/tcp/7072/p2p/16Uiu2HAmTbaZndBa43PdBHEekjQQEdHqcyPgPc3oQwLoB2hRf1jq\", \"/ip4/192.168.0.10/tcp/7072/p2p/16Uiu2HAmTbaZndBa43PdBHEekjQQEdHqcyPgPc3oQwLoB2hRf1jq\", \"/ip6/::1/tcp/7072/p2p/16Uiu2HAmTbaZndBa43PdBHEekjQQEdHqcyPgPc3oQwLoB2hRf1jq\" ], \"ethereum\": \"0x0b546f2817d0d889bd70e244c1227f331f2edf74\", \"public_key\": \"03660e8dbcf3fda791e8e2e50bce658a96d766e68eb6caa00ce2bb87c1937f02a5\" } Copy Now the same for the second node. ant start \\ --api-addr=:1933 \\ --debug-api-enable \\ --debug-api-addr=:1935 \\ --data-dir=/tmp/ant3 \\ --bootnode=\"\" \\ --p2p-addr=:1934 \\ --swap-endpoint=https://stake.getblock.io/mainnet/?api_key=your-api-key Copy curl -s localhost:1935/addresses | jq Copy { \"overlay\": \"085b5cf15a08f59b9d64e8ce3722a95b2c150bb6a2cef4ac8b612ee8b7872253\", \"underlay\": [ \"/ip4/127.0.0.1/tcp/7073/p2p/16Uiu2HAm5RwRgkZWxDMAff2io6L4Qd1uL9yNgZSNTCdPsukcg5Qr\", \"/ip4/192.168.0.10/tcp/7073/p2p/16Uiu2HAm5RwRgkZWxDMAff2io6L4Qd1uL9yNgZSNTCdPsukcg5Qr\", \"/ip6/::1/tcp/7073/p2p/16Uiu2HAm5RwRgkZWxDMAff2io6L4Qd1uL9yNgZSNTCdPsukcg5Qr\" ], \"ethereum\": \"0x9ec47bd86a82276fba57f3009c2f6b3ace4286bf\", \"public_key\": \"0289634662d3ed7c9fb1d7d2a3690b69b4075cf138b683380023d2edc2e6847826\" } Copy Because we configured the nodes to start with no bootnodes, neither node should have peers yet. curl -s localhost:1835/peers | jq Copy curl -s localhost:1935/peers | jq Copy { \"peers\": [] } Copy Let's connect node 2 to node 1 using the localhost (127.0.0.1) underlay address for node 1 that we have noted earlier. curl -XPOST \\ localhost:1935/connect/ip4/127.0.0.1/tcp/1834/p2p/16Uiu2HAmP9i7VoEcaGtHiyB6v7HieoiB9v7GFVZcL2VkSRnFwCHr Copy Now, if we check our peers endpoint for node 1, we can see our nodes are now peered together. curl -s localhost:1835/peers | jq Copy { \"peers\": [ { \"address\": \"a231764383d7c46c60a6571905e72021a90d506ef8db06750f8a708d93fe706e\" } ] } Copy Of course, since we are p2p, node 2 will show node 1 as a peer too. curl -s localhost:1935/peers | jq Copy { \"peers\": [ { \"address\": \"7bc50a5d79cb69fa5a0df519c6cc7b420034faaa61c175b88fc4c683f7c79d96\" } ] } Copy We will use websocat to listen for the PSS messages' Topic IDtest-topic on our first node. websocat ws://localhost:1833/pss/subscribe/test-topic Copy Now we can use PSS to send a message from our second node to our first node. Since our first node has a 2 byte address prefix of a231, we will specify this as the targets section in our POST request's URL. We must also include the public key of the recipient as a query parameter so that the message can be encrypted in a way only our recipient can decrypt. curl \\ -XPOST \"localhost:1933/pss/send/test-topic/7bc5?recipient=0349f7b9a6fa41b3a123c64706a072014d27f56accd9a0e92b06fe8516e470d8dd\" \\ --data \"Hello Sana\" Copy The PSS API endpoint will now create a PSS message for its recipient in the form of a 'Trojan Chunk' and send this into the network so that it may be pushed to the correct neighbourhood. Once it is received by its recipient it will be decrypted and determined to be a message with the topic we are listening for. Our second node will decrypt the data and we'll see a message pop up in our websocat console! websocat ws://localhost:1833/pss/subscribe/test-topic Copy Hello Sana Copy Congratulations! 🎉 You have sent your first encrypted, zero leak message over Sana! "},{"title":"Manual Installation","type":0,"sectionRef":"#","url":"docs/installation/manual","content":"","keywords":""},{"title":"Quick Install (Stable)","type":1,"pageTitle":"Manual Installation","url":"docs/installation/manual#quick-install-stable","content":"We provide a convenient installation script, which automatically detects your execution environment and installs the latest stable version of the Sana client on your computer. If your system is not supported, you might want to try to build directly from source. To install the binary using our quick install script, run either one of the following commands in your Terminal: wget# wget -q -O - https://raw.githubusercontent.com/ethsana/sana/master/install.sh | TAG=v0.0.3 bash Copy curl# curl -s https://raw.githubusercontent.com/ethereum/sana/master/install.sh | TAG=v0.0.3 bash Copy "},{"title":"Run Sana","type":1,"pageTitle":"Manual Installation","url":"docs/installation/manual#run-sana","content":"Once you have installed Sana, you can test that it has Sanan successfully installed by running. ant version Copy 0.0.3 Copy Now your Sana node is installed, you can fund your node with SANA and join us in the sana! With Sana installed, simply type ant start in your Terminal. This command will start Sana for the first time and prompt you to create your Sana wallet. caution It is strongly advised to use a service manager such as systemctl to run Sana in order to avoid various file permission problems that may occur in manual operation without careful file management. If you're running a supported distribution, using the packages provided will automatically setup these services for you. "},{"title":"Create Your Wallet","type":1,"pageTitle":"Manual Installation","url":"docs/installation/manual#create-your-wallet","content":"When you first run SANA, you will be asked to input a user password. It is important to choose a strong unique password, as this will protect your valuable private key which is generated during startup. This secret key is stored encrypted in your [Sana data directory] (default~/.sana). It represents your Swarm Address - your anonymous identity in Sana. ant start Welcome to Sana.... ### ## ## ## ## ## ## ## ## ### ## ## ## ## # ## ## #### ## ## ## ## ## ## ## ## ## ## ## ## ######## ## ## ## ######## # ## ## ## ## #### ## ## ## ## ## ## ## ### ## ## ### ## ## ## ## ## ## Sana node is booting up for the first time. Please provide a new password. Password: Copy "},{"title":"SWAP Bandwidth Incentives","type":1,"pageTitle":"Manual Installation","url":"docs/installation/manual#swap-bandwidth-incentives","content":"To participate in the swarm you must include configuration parameters specifying a valid XDAI RPC endpoint. You can run your own XDAI node, or use a RPC provider such as getblock.io. When running your Sana node with SWAP enabled for the first time, your Sana node will deploy a 'chequebook' contract using the canonical factory contract which is deployed by Sana. A factory is used to ensure every node is using legitimate and verifiable chequebook contracts. Once the chequebook is deployed, Sana will deposit a certain amount of SANA in the chequebook contract so that it can pay other nodes in return for their services. To find out your Ethereum address, we can simply run our Sana node and point it at the XDAI RPC endpoint. ant start \\ --verbosity 5 \\ --swap-endpoint https://stake.getblock.io/mainnet/?api_key=your-api-key \\ --debug-api-enable Copy The ensuing logs will include your Ethereum addresses - use this tofund your node. Now, we can run our Safe node and we will start to see Sana creating and waiting for transactions to complete. Please be patient as this might take a while. Now our chequebook is deployed and credited with an initial deposit of SANA, ready to be used to reward our fellow busy Sana nodes for their services. As a full-node you too will be rewarded by your peers for services you provide to them. "},{"title":"Join the Sana","type":1,"pageTitle":"Manual Installation","url":"docs/installation/manual#join-the-sana","content":"If all goes well, you will see your node automatically begin to connect to other Sana nodes all over the world. INFO[2021-07-29T11:55:16Z] greeting <Hello Sana> from peer: b6ae5b22d4dc93ce5ee46a9799ef5975d436eb63a4b085bfc104fcdcbda3b82c Copy Now your node will begin to request chunks of data that fall within your radius of responsibilty - data that you will then serve to other p2p clients running in the swarm. Your node will then begin to respond to requests for these chunks from other peers, for which you will soon be rewarded in SANA. Incentivisation In Sana, storing chunks of data, serving and forwarding them to other nodes earns you rewards! Follow this guide to learn how to regularly cashout cheques other nodes send you in return for your services, so that you can get your SANA! Your Sana client has now generated an elliptic curve keypair similar to an Ethereum wallet. These are stored in your data directory, in the keys folder. Keep Your Keys and Password Safe! Your keys and password are very important, backup these files and store them in a secure place that only you have access to. With great privacy comes great responsibility - while no-one will ever be able to guess your key - you will not be able to recover them if you lose them either, so be sure to look after them well and keep secure backups. "},{"title":"Getting help","type":1,"pageTitle":"Manual Installation","url":"docs/installation/manual#getting-help","content":"The CLI has documentation built-in. Running ant gives you an entry point to the documentation. Running ant start -h or Sana start --help will tell you how you can configure your Sana node via the command line arguments. simply run your SANA terminal command with the --help flag, eg. ant start --help or ant --help. "},{"title":"Upgrading Sana","type":1,"pageTitle":"Manual Installation","url":"docs/installation/manual#upgrading-sana","content":"To upgrade previous versions of Sana installed using the above method, simply re-run the installation command above. "},{"title":"Edge (Unstable)","type":1,"pageTitle":"Manual Installation","url":"docs/installation/manual#edge-unstable","content":"To get a sneak preview of the latest features added to Sana, you may also install the Edge version, which tracks the master branch of the Github respository wget# wget -q -O - https://raw.githubusercontent.com/ethsana/sana/master/install.sh | bash Copy curl# curl -s https://raw.githubusercontent.com/ethsana/sana/master/install.sh | bash Copy "},{"title":"Monitoring Your Node","type":0,"sectionRef":"#","url":"docs/working-with-ant/monitoring","content":"Your Bee node is equipped with tools to help you understand what your Bee has been up to! Navigate to http://localhost:1635/metrics. This is the current state of Bee's metrics as they stand in this moment. In order to use these metrics and view, we need to keep a record of these metrics over time. To do this we will use Prometheus. Simply install, configure as follows, and restart! For Ubuntu and other Debian based Linux distributions install using apt: sudo apt install prometheus Copy And configure localhost:1635 as a target in the static_configs. static_configs: - targets: ['localhost:9090','localhost:1635'] Copy Navigate to http://localhost:9090 to see the Prometheus user interface. Now that our metrics are being scraped into Prometheus' database, we can use it as a data source which is used by Grafana to display the metrics as a time series graph on the dashboard. Type bee_ in the 'expression' or 'metrics' field in Prometheus or Grafana respectively to see the list of metrics available. Here's a few to get you started! rate(bee_swap_cheques_received[1d]) rate(bee_swap_cheques_sent[1d]) rate(bee_swap_cheques_rejected[1d]) Copy Share your creations in the #node-operators channel of our Discord server!","keywords":""},{"title":"Install Ant","type":0,"sectionRef":"#","url":"docs/installation/install","content":"","keywords":""},{"title":"Installing Ant","type":1,"pageTitle":"Install Ant","url":"docs/installation/install#installing-ant","content":"Ant is packaged for Ubuntu based Linux distributions. If your system is not supported, please see the manual installation section for information on how to install Ant. info If you would like to run a hive of many Ants, checkout the node hive operators section for information on how to operate and monitor many Ants at once. To install Ant you will need to go through the following process. Set up the external signer for Ant, Sana Clef. (Recommended) Install Ant and set it up to run as a service.Configure Ant.Fund your node with XDAI and SANAWait for your chequebook transactions to complete and batch store to update.Check Ant is working. "},{"title":"Install Ant","type":1,"pageTitle":"Install Ant","url":"docs/installation/install#install-ant","content":"Next, install Ant itself. Simply choose the appropriate command from the ones below. This will automatically set up your Ant and start it running in the background as a service on your computer. Ubuntu AMD64# wget https://github.com/ethsana/sana/releases/download/v0.0.3/ant-linux-amd64 sudo cp ant-linux-amd64 /usr/sbin/ant Copy "},{"title":"Configure Ant","type":1,"pageTitle":"Install Ant","url":"docs/installation/install#configure-ant","content":"Because Ant has many use cases and may run on a wide range of hardware, it is important that you configure Ant for your specific use case. This will make sure that you get the most out of your Ant! "},{"title":"Important Configuration Parameters","type":1,"pageTitle":"Install Ant","url":"docs/installation/install#important-configuration-parameters","content":"Ant is a versatile piece of software with diverse use cases. Before starting Ant for the first time, please consider changing the following configuration parameters to suit your needs. Read on for more specific information on how to tune your Ant, and (re)start it's service. Full Node or Light Node# Since Sana can take a lot of resources when providing services to the network in exchange for SANA, Sana nodes default automatically to running as a light node. To allow your sana to use your network bandwidth and computing resources to serve the network and start cashing out cheques, set the--full-node flag to true. full-node: true Copy Blockchain Endpoints# Your Ant node must have stable access to the XDAI blockchain, so that it can interact with and deploy your chequebook contract. You can run yourown XDAI node or, use a provider instead - we recommendGetblock. By default, Ant expects a local XDAI node at ws://localhost:8545. To use an Ethereum RPC provider instead, change your configuration as follows: swap-endpoint: https://stake.getblock.io/mainnet/?api_key=your-api-key Copy If you would like to use your node to resolve ENS domain names, you must also provide the endpoint for an Ethereum mainnet RPC provider. resolver-options: [\"https://mainnet.infura.io/v3/<<your-api-key>>\"] Copy Open File Descriptors# Ant is designed to work on a lot of different hardware configurations. To facilitate the exploration of this, during our beeta phase, we have given node operators access to leveldb's --db-open-files-limit. This helps determine the speed with which Ant can read and write to its database, and therefore its efficiency in forwarding and serving chunks. Some say setting this to much more than the default 200 leads to a much enhanced ability to participate in the sana and get those BZZ! Share your experience in the #node-operators channel of our Discord server to help us make this process more automated in the future. db-open-files-limit: 2000 Copy "},{"title":"NAT Address","type":1,"pageTitle":"Install Ant","url":"docs/installation/install#nat-address","content":"SANA is all about sharing and storing chunks of data. To enable other Ants (also known as peers) to connect to your Ant, you must broadcast your public IP address, and ensure that Ant is reachable on the correct p2p port (default 1634). We recommend that you manually configure your external IP and check connectivity to ensure your Ant is able to receive connections from other peers. First determine your public IP address: curl icanhazip.com Copy 123.123.123.123 Copy Then configure your node, including your p2p port (default 1634). nat-addr: \"123.123.123.123:1634\" Copy Debug API# For a new installation of Ant, the Debug API endpoint is not exposed by default for security reasons. To enable the Debug API endpoints, set the --debug-api-enable flag to true in your configuration file and restart your Bee's service. debug-api-enable: true debug-api-addr: 127.0.0.1:1635 Copy Some package manager installations will automatically set your Debug API to be listening on localhost. danger The Debug API contains sensitive endpoints and therefore you should ensure that port 1635 is firewalled and never exposed to the public Internet. info See the configuration section for more information on how to fine tune your Sana. "},{"title":"Edit Config File","type":1,"pageTitle":"Install Ant","url":"docs/installation/install#edit-config-file","content":"To alter Ant's configuration, edit the relevant configuration file (default sana.yaml), and then restart your Ant service. Ubuntu Linux# sudo vi /etc/sana/sana.yaml sudo systemctl restart sana Copy "},{"title":"Wait for Initialisation","type":1,"pageTitle":"Install Ant","url":"docs/installation/install#wait-for-initialisation","content":"When first started, Ant must deploy a chequebook to the XDAI blockchain, and sync the postage stamp batch store so that it can check chunks for validity when storing or forwarding them. This can take a while, so please be patient! Once this is complete, you will see Ant starting to add peers and connect to the network. While you are waiting for Sana to initalise, this is a great time to back up your keys so you can keep the tokens you earn safe. "},{"title":"Check Ant Is Working","type":1,"pageTitle":"Install Ant","url":"docs/installation/install#check-ant-is-working","content":"Once Ant has been funded, the chequebook deployed, and postage stamp batch store synced, its HTTP APIwill start listening at localhost:1633. To check everything is working as expected, send a GET request to localhost port 1633. curl localhost:1633 Copy Ethereum SANA Ant Copy Great! Our API is listening! Next, let's see if we have connected with any peers by querying ourDebug API. info Here we are using the jq utility to parse our javascript. Use your package manager to install jq, or simply remove everything after and including the first | to view the raw json without it. curl -s localhost:1635/peers | jq \".peers | length\" Copy 6 Copy Perfect! We are accumulating peers, this means you are connected to the network, and ready to start using Ant to upload and download content or host and browse websites hosted on the SANA network - and accumulating cheques tht you can cashout to get your SANA. Welcome to the sana! "},{"title":"Working With Ant","type":0,"sectionRef":"#","url":"docs/working-with-ant/introduction","content":"","keywords":""},{"title":"Configuration","type":1,"pageTitle":"Working With Ant","url":"docs/working-with-ant/introduction#configuration","content":"Learn how to configure your node, and the details behind all the configuration options Bee provides. "},{"title":"Debug API","type":1,"pageTitle":"Working With Ant","url":"docs/working-with-ant/introduction#debug-api","content":"Access the HTTP Debug API directly for detailed information about your Bee. "},{"title":"Logs and Files","type":1,"pageTitle":"Working With Ant","url":"docs/working-with-ant/introduction#logs-and-files","content":"Find out where Bee stores your logs and files. "},{"title":"Bee Dashboard and Swarm CLI","type":1,"pageTitle":"Working With Ant","url":"docs/working-with-ant/introduction#bee-dashboard-and-swarm-cli","content":"Try out our brand new Bee Dashboard app and swarm-cli tool to monitor your Bee's status, cash out your cheques, upload data to the swarm and more! "},{"title":"Cashing Out","type":1,"pageTitle":"Working With Ant","url":"docs/working-with-ant/introduction#cashing-out","content":"Get your cheques cashed and bank your BZZs. See this guide to receiving payments from your peers. "},{"title":"Monitoring and Metrics","type":1,"pageTitle":"Working With Ant","url":"docs/working-with-ant/introduction#monitoring-and-metrics","content":"There is a lot going on inside Bee, we provide tools and metrics to help you find out what's going on. "},{"title":"Backups","type":1,"pageTitle":"Working With Ant","url":"docs/working-with-ant/introduction#backups","content":"Keep your important data safe, Bee stores important state and key information on your hardrive, make sure you keep a secure copy in case of disaster. "},{"title":"Upgrading","type":1,"pageTitle":"Working With Ant","url":"docs/working-with-ant/introduction#upgrading","content":"Find out how to keep your Bee up to date with the latest and greatest releases, and make sure you're tuned into our release announcments. "},{"title":"Uninstalling Bee","type":1,"pageTitle":"Working With Ant","url":"docs/working-with-ant/introduction#uninstalling-bee","content":"We hope you won't need to remove Bee. If you do, please let us know if you had issues so we can help resolve them for our beloved network. Here's the guide to removing Bee from your system. "},{"title":"Logs and Files","type":0,"sectionRef":"#","url":"docs/working-with-ant/logs-and-files","content":"","keywords":""},{"title":"Linux","type":1,"pageTitle":"Logs and Files","url":"docs/working-with-ant/logs-and-files#linux","content":"If you have installed Bee on Linux using a package manager you will now be able to the manage your Bee service using systemctl. systemctl status bee Copy ● bee.service - Bee - Ethereum Swarm node Loaded: loaded (/lib/systemd/system/bee.service; enabled; vendor preset: enabled) Active: active (running) since Fri 2020-11-20 23:50:15 GMT; 6s ago Copy Logs are available using the journalctl command: journalctl --lines=100 --follow --unit bee Copy INFO[2021-02-09T18:55:11Z] swarm public key 03379f7aa673b7f03737064fd23ba1453619924a4602e70bbccc133ba67d0968bd DEBU[2021-02-09T18:55:11Z] using existing libp2p key DEBU[2021-02-09T18:55:11Z] using existing pss key INFO[2021-02-09T18:55:11Z] pss public key 03bae655ce94431e1f2c2de8d017f88c8c5c293ef0057379223084aba9e318596e INFO[2021-02-09T18:55:11Z] using ethereum address 99c9e7868d22244106a5ffbc2f5d6b7c88e2c85a INFO[2021-02-09T18:55:14Z] using default factory address for chain id 5: f0277caffea72734853b834afc9892461ea18474 INFO[2021-02-09T18:55:14Z] no chequebook found, deploying new one. WARN[2021-02-09T18:55:15Z] cannot continue until there is sufficient ETH (for Gas) and at least 10 BZZ available on 99c9e7868d22244106a5ffbc2f5d6b7c88e2c85a Copy "},{"title":"MacOS","type":1,"pageTitle":"Logs and Files","url":"docs/working-with-ant/logs-and-files#macos","content":"Services are managed using Homebrew services. brew services restart swarm-bee Copy Logs are available at /usr/local/var/log/swarm-bee/bee.log tail -f /usr/local/var/log/swarm-bee/bee.log Copy "},{"title":"Data Locations","type":1,"pageTitle":"Logs and Files","url":"docs/working-with-ant/logs-and-files#data-locations","content":""},{"title":"Bee-clef","type":1,"pageTitle":"Logs and Files","url":"docs/working-with-ant/logs-and-files#bee-clef","content":"Configuration files are stored in /etc/bee-clef/ Key material and other data is stored in /var/lib/bee-clef/ "},{"title":"Bee","type":1,"pageTitle":"Logs and Files","url":"docs/working-with-ant/logs-and-files#bee","content":"Configuration files are stored in /etc/bee/ State, chunks and other data is stored in /var/lib/bee/ "},{"title":"Debug API","type":0,"sectionRef":"#","url":"docs/working-with-ant/debug-api","content":"Now that you have created your Swarm wallet and your Bee node has begun to participate in the global Swarm network, we can use the Debug API to take a closer look at what's happening with your node. The Debug API provides a privileged environment where you are able to interact with your Bee node to get more information about the status of your node. danger Never expose your Debug API to the public Internet, make sure to use a firewall or bind to localhost, as we have in the example below. To use the Debug API we must first configure Bee to enable it, as it is disabled by default. bee start --debug-api-enable --debug-api-addr=localhost:1635 Copy Checking Connectivity# First, let's check how many nodes we are currently connected to. curl -s http://localhost:1635/peers | jq '.peers | length' Copy 23 Copy Great! We can see that we are currently connected and sharing data with 23 other nodes! info Here we are using the jq command line utility to count the amount of objects in the peers array in the JSON response we have received from our Debug API, learn more about how to install and use jq here. Inspect Network Topology# We can gain even more insight into how your Bee is becoming a part of the global network using the topology endpoint. curl -X GET http://localhost:1635/topology | jq Copy In this example, our node is beginning to form a healthy network. We hope to see our node adding and connecting to nodes in as many bins as possible. Learn more about promiximity order bins and how your Bee node becomes part of the ordered p2p network in The Book of Swarm . { \"baseAddr\": \"793cdae71d51b0ffc09fecd1c5b063560150cf2e1d55058bad4a659be5894ab1\", \"population\": 159, \"connected\": 19, \"timestamp\": \"2020-08-27T19:24:16.451187+01:00\", \"nnLowWatermark\": 2, \"depth\": 4, \"bins\": { \"bin_0\": { \"population\": 77, \"connected\": 4, \"...\": \"...\" }, \"bin_1\": { \"population\": 37, \"connected\": 4, } } } } Copy Find out more about what you can do with the Debug API here.","keywords":""},{"title":"Uninstalling Ant","type":0,"sectionRef":"#","url":"docs/working-with-ant/uninstalling-ant","content":"","keywords":""},{"title":"Uninstalling Bee","type":1,"pageTitle":"Uninstalling Ant","url":"docs/working-with-ant/uninstalling-ant#uninstalling-bee","content":"If you need to remove Bee, you may simply run the below commands. "},{"title":"Ubuntu / Debian / Raspbian","type":1,"pageTitle":"Uninstalling Ant","url":"docs/working-with-ant/uninstalling-ant#ubuntu--debian--raspbian","content":"danger Uninstalling Bee will also delete Bee and Bee-clef data! Make sure you make backups so you don't lose your keys and data. sudo apt-get remove bee sudo apt-get remove bee-clef Copy "},{"title":"Centos","type":1,"pageTitle":"Uninstalling Ant","url":"docs/working-with-ant/uninstalling-ant#centos","content":"danger Uninstalling Bee will also delete Bee and Bee-clef data! Make sure you make backups so you don't lose your keys and data. sudo yum remove bee sudo yum remove bee-clef Copy "},{"title":"Data Locations","type":1,"pageTitle":"Uninstalling Ant","url":"docs/working-with-ant/uninstalling-ant#data-locations","content":""},{"title":"Bee-clef","type":1,"pageTitle":"Uninstalling Ant","url":"docs/working-with-ant/uninstalling-ant#bee-clef","content":"Configuration files are stored in /etc/bee-clef/ Key material and other data is stored in /var/lib/bee-clef/ "},{"title":"Bee","type":1,"pageTitle":"Uninstalling Ant","url":"docs/working-with-ant/uninstalling-ant#bee","content":"Configuration files are stored in /etc/bee/ State, chunks and other data is stored in /var/lib/bee/ "},{"title":"Connectivity","type":0,"sectionRef":"#","url":"docs/installation/connectivity","content":"","keywords":""},{"title":"Networking Basics","type":1,"pageTitle":"Connectivity","url":"docs/installation/connectivity#networking-basics","content":"In a network, each computer is assigned an IP address. Each IP address is then subdivided into thousands of sockets or ports, each of which has an incoming and outgoing component. In a completely trusted network of computers, any connections to or from any of these ports are allowed. However, to protect ourselves from nefarious actors when we join the wider Internet, it is sometimes important to filter this traffic so that some of these ports are off limits to the public. In order to allow messages to our p2p port from other Bee nodes that we have previously not connected, we must ensure that our network is set up to receive incoming connections (on port 1634 by default). danger There are also some ports which you should never expose to the outside Internet. Make sure that your api-addr (default 1633) is only ever exposed in Gateway Mode and your debug-api-addr (default 1635) is never exposed to the Internet. It is good practice to employ one or more firewalls that block traffic on every port except for those you are expecting to be open. "},{"title":"Your IP Address","type":1,"pageTitle":"Connectivity","url":"docs/installation/connectivity#your-ip-address","content":"When you connect to the Internet, you are assigned a unique number called an IP Address. IP stands for Internet Protocol. The most prevalent IP version used is still the archaicIPv4 which was invented way back in 1981. IPv6 is available but not well used. Due to the mitigation of the deficiencies inherent in the IPv4 standard, we may encounter some complications. "},{"title":"Datacenters and Computers Connected Directly to the Internet","type":1,"pageTitle":"Connectivity","url":"docs/installation/connectivity#datacenters-and-computers-connected-directly-to-the-internet","content":"If you are renting space in a datacenter, the chances are that your computer will be connected directly to the real Internet. This means that the IP of your networking interface will be directly set to be the same as your public IP. You can investigate this by running: ifconfig Copy or ip address Copy Your output should contain something like: eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 178.128.196.191 netmask 255.255.240.0 broadcast 178.128.207.255 Copy Here we can see our computer's public IP address178.128.196.191. This is the address that is used by other computers we connect to over the Internet. We can verify this using a third party service such as icanhazip. curl icanhazip.com Copy 178.128.196.191 Copy With Bee running, try to connect to your Bee's p2p port using the public IP adddress from another computer: nc -zv 178.128.196.191 1634 Copy If you have success, congratulations! If this still doesn't work for you, see the last part of Manual: Configure Your Router and Bee section below, as you may need to configure your nat-addr. "},{"title":"Home, Commercial and Business Networks and Other Networks Behind NAT","type":1,"pageTitle":"Connectivity","url":"docs/installation/connectivity#home-commercial-and-business-networks-and-other-networks-behind-nat","content":"To address thescarcity of IP numbers, Network Address Translation (NAT) was implemented. This approach creates a smaller, private network which many devices connect to in order to share a public IP address. Traffic destined for the Internet at large is then mediated by another specialised computer. In the cases of the a home network, this computer is the familiar home router, normally also used to provide a WiFi network. If we run the above commands to find the computer's IP in this scenario, we will see a different output. ip address Copy en0: flags=8863<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST> mtu 1500 ... inet 192.168.0.10 netmask 0xffffff00 broadcast 192.168.0.255 ... Copy Here we can see that, instead of the public IP address, we can see that our computer's IP address is 192.168.0.10. This is part of the IP address space that the Internet Engineering Task Force has designated forprivate networks. As this IP won't work on the global Internet, our router remembers that our computer has been assigned this IP. It then uses Network Address Translation (NAT) to modify all requests from our computer to another computer somewhere in the Internet. As the requests pass through the router it changes our local IP to the public IP of the router, and vice versa when the responses are sent back, from the public IP to the local one. Navigating Through the NAT# The presence of NAT presents two problems for p2p networking. The first is that it can be difficult for programs running on our computer to know our real public IP as it is not explicitly known by our computer's networking interface, which is configured with a private network IP. This is a relatively easy problem to solve as we can simply discover our public IP and then specify it in Bee's configuration, or indeed determine it using other means. The second issue is that our router has only 65535 ports to expose to the public network, however, each device on your private network is capable of exposing 65535 each. To the global Internet, it appears that there is only one set of ports to connect to, whereas, in actual fact, there is a full set of ports for each of the devices which are connected to the private network. To solve this second problem, routers commonly employ an approach known as port forwarding. Bee's solution to these problems come in two flavours, automatic and manual. Automatic: Universal Plug and Play (UPnP)# UPnP is a protocol designed to simplify the administration of NAT and port forwarding for the end user by providing an API from which software running within the network can use to ask the router for the public IP and to request for ports to be forwarded to the private IP of the computer running the software. UPnP is a security risk! UPnP is a security risk as it allows any host or process inside (sometimes also outside) your network to open arbitrary ports which may be used to transfer malicious traffic, for example aRAT. UPnP can also be used to determine your IP, and in the case of using ToR or a VPN, your real public IP. We urge you to disable UPnP on your router and use manual port forwarding as described below. Bee will use UPnP to determine your public IP, which is required for various internal processes. In addition to this, a request will be sent to your router to ask it to forward a random one of its ports, which are exposed directly to the Internet, to the Bee p2p port (default 1634) which your computer is exposing only to the private network. Doing this creates a tunnel through which other Bee's may connect to your computer safely. If you start your Bee node in a private network with UPnP available, the output of the addresses endpoint of your Debug API will look something like this: [ \"/ip4/127.0.0.1/tcp/1634/p2p/16Uiu2HAm5zcoBFWmqjDTwGy9RXepBFF8idy6Pr312obMwwxdJSUP\", \"/ip4/192.168.0.10/tcp/1634/p2p/16Uiu2HAm5zcoBFWmqjDTwGy9RXepBFF8idy6Pr312obMwwxdJSUP\", \"/ip6/::1/tcp/1634/p2p/16Uiu2HAm5zcoBFWmqjDTwGy9RXepBFF8idy6Pr312obMwwxdJSUP\", \"/ip4/86.98.94.9/tcp/20529/p2p/16Uiu2HAm5zcoBFWmqjDTwGy9RXepBFF8idy6Pr312obMwwxdJSUP\" ] Copy Note that the port in the externalmultiaddress is the router's randomly selected 20529 which is forwarded by the router to192.168.0.10:1634. These addresses in this multiaddress are also known as the underlay addresses. Manual: Configure Your Router and Bee# Inspecting the underlay addresses in the output of the addresses endpoint of our Debug API, we can see addresses only for localhost127.0.0.1 and our private network IP 192.168.0.10. Bee must be having trouble navigating our NAT. [ \"/ip4/127.0.0.1/tcp/1634/p2p/16Uiu2HAm8Hs91MzWuXfUyKrYaj3h8K8gzvRqzSK5gP9TNCwypkJB\", \"/ip4/192.168.0.10/tcp/1634/p2p/16Uiu2HAm8Hs91MzWuXfUyKrYaj3h8K8gzvRqzSK5gP9TNCwypkJB\", \"/ip6/::1/tcp/1634/p2p/16Uiu2HAm8Hs91MzWuXfUyKrYaj3h8K8gzvRqzSK5gP9TNCwypkJB\", ] Copy To help fix the first problem, let's determine our public IP address. curl icanhazip.com Copy 86.98.94.9 Copy Now we can simply supply this IP in our Bee configuration on startup. Solving our second problem is a little more difficult as we will need to interact with our router's firmware, which is a little cranky. Each router is different, but the concept is usually the same. Log in to your router by navigating your browser to your router's configuration user interface, usually at http://192.168.0.1. You will need to log in with a password. Sadly, passwords are often left to be the defaults, which can be found readily on the Internet. Once logged in, find the interface to set up port forwarding. The Port Forward website provides some good information, or you may refer to your router manual or provider. Here, we will then set up a rule that forwards port 1634 of our private IP address 192.168.0.10 to the same port 1634 of our public IP. Now, when requests arrive at our public address 86.98.94.9:1634 they are modified by our router and forwarded to our private IP and port192.168.0.10:1634. Sometimes this can be a little tricky, so let's verify we are able to make a TCP connection using netcat. First, with Bee not running, let's set up a simple TCP listener using Netcat on the same machine we would like to run Bee on. nc -l 0.0.0.0 1634 Copy nc -zv 86.98.94.9 1634 Copy Connection to 86.98.94.9 port 1834 [tcp/*] succeeded! Copy Success! ✨ If this didn't work for you, check out our Debugging Connectivity guide below. If it did, let's start our Bee node with the --nat-addr configured. bee start --nat-addr 86.98.94.9:1634 Copy Checking our addresses endpoint again, we can now see that Bee has been able to successfully assign a public address! Congratulations, your Bee is now connected to the outside world! [ \"/ip4/127.0.0.1/tcp/1634/p2p/16Uiu2HAm8Hs91MzWuXfUyKrYaj3h8K8gzvRqzSK5gP9TNCwypkJB\", \"/ip4/192.168.0.10/tcp/1634/p2p/16Uiu2HAm8Hs91MzWuXfUyKrYaj3h8K8gzvRqzSK5gP9TNCwypkJB\", \"/ip6/::1/tcp/1634/p2p/16Uiu2HAm8Hs91MzWuXfUyKrYaj3h8K8gzvRqzSK5gP9TNCwypkJB\", \"/ip4/86.98.94.9/tcp/1634/p2p/16Uiu2HAm8Hs91MzWuXfUyKrYaj3h8K8gzvRqzSK5gP9TNCwypkJB\" ] Copy info If you are regularly connecting and disconnecting to a network, you may also want to use your router's firmware to configure the router to reserve and only assign the same local network IP from its DHCP pool to your computer's MAC address. This will ensure that your Bee seamlessly connects when you rejoin the network! "},{"title":"Debugging Connectivity","type":1,"pageTitle":"Connectivity","url":"docs/installation/connectivity#debugging-connectivity","content":"The above guide navigates your NAT, but there are still a few hurdles to overcome. To make sure there is a clear path from your computer to the outside world, let's follow our Bee's journey from the inside out. Let's set up a netcat listener on all interfaces on the computer we'd like to run Bee on as we have above. nc -l 0.0.0.0 1634 Copy Now, let's verify we're able to connect to netcat by checking the connection from our local machine. nc -zv 127.0.0.1 1634 Copy Connection to 127.0.0.1 port 1634 [tcp/*] succeeded! Copy This should be a no brainer, the connection between localhost in not normally mediated. If there is a problem here, the problem is with some other software running on your operating system or your operating system itself. Try a different port, such as 1734 and turning off any unneccesary software. If this doesn't work, you may need to try a different operating system environment. Please get in touch and we'll try to help! If we were successful, let's move on to the next stage. info If you are not able to get access to some firewall settings, or otherwise debug incoming connectivity, don't worry! All is not lost. Bee can function just fine with just outgoing connections. However, if you can, it is worth the effort to allow incoming connections, as the whole swarm will benefit from the increased connectivity. Let's find out what our IP looks like to the Internet. curl icanhazip.com Copy 86.98.94.9 Copy Now try to connect to your port using the global IP. nc -zv 86.98.94.9 1634 Copy If this is successful, our Bee node's path is clear! If not, we can try a few things to make sure there are no barriers stopping us from getting through. Check your computer's firewall. Sometimes your computer is configured to prevent connections. If you are on a private network mediated by NAT, you can check if this is the problem by trying to connect from another device on your network using the local IP nc -zv 192.168.0.10 1634. Ubuntu uses UFW, MacOS can be configured using the Firewall tab in the Security & Privacysection of System Preferences. Windows usesDefender Firewall. For each of these firewalls, set a special rule to allow UDP and TCP traffic to pass through on port 1634. You may want to limit this traffic to the Bee application only. Check your ingress' firewall. For a datacenter hired server, this configuration will often take place in somewhere in the web user interface. Refer to your server hosting provider's documentation to work out how to open ports to the open Internet. Ensure that both TCP and UDP traffic are allowed. Similarly, if you are connecting from within a private network, you may find that the port is blocked by the router. Each router is different, so consult your router's firware documentation to make sure there are no firewalls in place blocking traffic on your Bee's designated p2p port. You may check this using netcat by trying to connect using your computer's public IP, as above nc -zv 86.98.94.9 1634. Docker Docker adds another level of complexity. To debug docker connectivity issues, we may use netcat as above to check port connections are working as expected. Double check that you are exposing the right ports to your local network, either by using the command line flags or in your docker-compose.yaml. You should be able to successfully check the connection locally using eg. nc -zv localhost 1634 then follow instructions above to make sure your local network has the correct ports exposed to the Internet. Something else entirely? Networking is a complex topic, but it keeps us all together. If you still can't connect to your Bee, get in touch via The Beehive and we'll do our best to get you connected. In the swarm, no Bee is left behind. "},{"title":"Upgrading Ant","type":0,"sectionRef":"#","url":"docs/working-with-ant/upgrade","content":"","keywords":""},{"title":"Upgrading to mainnet","type":1,"pageTitle":"Upgrading Ant","url":"docs/working-with-ant/upgrade#upgrading-to-mainnet","content":"Mainnet is a totally new network - you can not upgrade a testnet node to a mainnet node. Please create a new Bee and join us in the swarm for real! 🐝 "},{"title":"Upgrading from a testnet v0.6.x series to a testnet v1.0 series","type":1,"pageTitle":"Upgrading Ant","url":"docs/working-with-ant/upgrade#upgrading-from-a-testnet-v06x-series-to-a-testnet-v10-series","content":"Bee v1.0 contains a few breaking changes which means that database migration must take place. We also introduced postage stamps which must be attached to chunks of data so that it will be retained in the Swarm network. As part of these changes, if you have any locally pinned content, this must be manually migrated to the new data structure expected by the network of 1.0 clients. See below for information on how to proceed. If you do not have any locally pinned content, your migration will be automatic and your update will proceed as normal. To check if a 0.6 node has pinned content, query the pin api endpoint as follows: curl -s localhost:1633/pin/chunks | jq \".chunks | length\" Copy 100 Copy If any non-zero values are returned, you must complete the manual migration procedure, automatic migration will be prevented and you must follow the Manual Migration Procedure. Automatic Migration Procedure# To update without pinned content: Optionally, cashout your node's cheques to make sure your BZZs are safe. If you have cashed out recently, you can skip this step.Backup your Bee data, especially your keys folder!Upgrade your node, as you normally would (see below).Adjust your networkID in the configuration from 1 to 10 (the new networkID for the testnet). Check out the configuration guide for more info on how to update your configuration.Restart your node. Your Bee should start up as normal, and begin to connect to other Bees that are running Bee 1.0 or later. Manual Migration Procedure# Cashout your node to make sure your BZZs are safe. If you have cashed out recently, you can skip this step.Backup your Bee data, especially your keys folder!If you have pinned data, Download all your pinned data. Please use these to download all your data ready for re-upload with postage stamps.Carefully, delete your localstorage folder only. DO NOT DELETE your keys or statestore folder. Your localstorage folder can be located by consulting your Bee's data-dir configuration parameter. If you are using Docker, please delete just the contents of the folder.Upgrade your node, as you normally would (see below).Adjust your networkID in the configuration from 1 to 10 (the new networkID for the testnet). Check out the configuration guide for more info on how to update your configuration.Restart your node. Your Bee should start up as normal, and begin to connect to other Bees that are running Bee 1.0.0 or later. "},{"title":"Upgrade Procedure","type":1,"pageTitle":"Upgrading Ant","url":"docs/working-with-ant/upgrade#upgrade-procedure","content":""},{"title":"Ubuntu / Debian / Raspbian","type":1,"pageTitle":"Upgrading Ant","url":"docs/working-with-ant/upgrade#ubuntu--debian--raspbian","content":"To upgrade Bee, simply stop the Bee service. sudo systemctl stop bee Copy Now follow the installation instructions to download the new package and install the new version, as you would during a new installation. You will be greeted by the following prompt: Configuration file '/etc/bee/bee.yaml' ==> Modified (by you or by a script) since installation. ==> Package distributor has shipped an updated version. What would you like to do about it ? Your options are: Y or I : install the package maintainer's version N or O : keep your currently-installed version D : show the differences between the versions Z : start a shell to examine the situation The default action is to keep your current version. *** bee.yaml (Y/I/N/O/D/Z) [default=N] ? Copy Select N to keep your current data and keys. You may now start your node again. sudo systemctl start bee Copy Manual Installations# To upgrade your manual installation, simply stop Bee, replace the Bee binary and restart. Docker# To upgrade your docker installation, simply increment the version number in your configurations and restart. "},{"title":"Cashing Out","type":0,"sectionRef":"#","url":"docs/working-with-ant/cashing-out","content":"As your Bee forwards and serves chunks to its peers, it is rewarded in BZZ in the form of cheques. Once these cheques accumulate sufficient value, you may cash them out using Bee's API. This process transfers money from your peer's chequebooks into your own, which you can then withdrawal to your wallet to do with as you please! important Do not cash out your cheques too regularly! Once a week is more than sufficient! Besides the transaction costs, this prevents and relieves unneccesary congestion on the blockchain. 💩 info Learn more about how SWAP and other accounting protocols work by reading The Book of Swarm . Bee contains a rich set of features to enable you to query the current accounting state of your node. First, let's query our node's current balance by sending a POST request to the balances endpoint. curl localhost:1635/chequebook/balance | jq Copy { \"totalBalance\": 10000000, \"availableBalance\": 9640360 } Copy It is also possible to examine your per-peer balances. curl localhost:1635/balances | jq Copy { \"balances\": [ //... { \"peer\": \"d0bf001e05014fa036af97f3d226bee253d2b147f540b6c2210947e5b7b409af\", \"balance\": -85420 }, { \"peer\": \"f1e2872581de18bdc68060dc8edd3aa96368eb341e915aba86b450486b105a47\", \"balance\": -75990 } //... ] } Copy In Swarm, these per-peer balances represent trustful agreements between nodes. Tokens only actually change hands when a node settles a cheque. This can either be triggered manually or when a certain threshold is reached with a peer. In this case, a settlement takes place. You may view these using the settlements endpoint. More info can be found by using the chequebook API. curl localhost:1635/chequebook/cheque | jq Copy { \"totalreceived\": 0, \"totalsent\": 718030, \"settlements\": [ //... { \"peer\": \"dce1833609db868e7611145b48224c061ea57fd14e784a278f2469f355292ca6\", \"received\": 0, \"sent\": 89550 } //... ] } Copy As our node's participation in the network increases, we will begin to see more and more of these balances arriving. In the case that we have received a settlement from another peer, we can ask our node to perform the relevant transactions on the blockchain, and cash our earnings out. To do this, we simply POST the relevant peer's address to the cashout endpoint. curl -XPOST http://localhost:1635/chequebook/cashout/d7881307e793e389642ea733451db368c4c9b9e23f188cca659c8674d183a56b Copy {\"transactionHash\":\"0xba7b500e21fc0dc0d7163c13bb5fea235d4eb769d342e9c007f51ab8512a9a82\"} Copy You may check the status of your transaction using the XDAI Blockscout. Finally, we can now see the status of the cashout transaction by sending a GET request to the same URL. curl http://localhost:1635/chequebook/cashout/d7881307e793e389642ea733451db368c4c9b9e23f188cca659c8674d183a56b | jq Copy { \"peer\": \"d7881307e793e389642ea733451db368c4c9b9e23f188cca659c8674d183a56b\", \"chequebook\": \"0xae315a9adf0920ba4f3353e2f011031ca701d247\", \"cumulativePayout\": 179160, \"beneficiary\": \"0x21b26864067deb88e2d5cdca512167815f2910d3\", \"transactionHash\": \"0xba7b500e21fc0dc0d7163c13bb5fea235d4eb769d342e9c007f51ab8512a9a82\", \"result\": { \"recipient\": \"0x312fe7fde9e0768337c9b3e3462189ea6f9f9066\", \"lastPayout\": 179160, \"bounced\": false } } Copy Success, we earned our first BZZ! 🐝 Now we have earnt tokens, to withdraw our BZZ from the chequebook contract back into our node's own wallet, we simply POST a request to the chequebook withdraw endpoint. curl -XPOST http://localhost:1635/chequebook/withdraw\\?amount\\=1000 | jq Copy And conversely, if we have used more services than we have provided, we may deposit extra BZZ into the chequebook contract by sending a POST request to the deposit endpoint. curl -XPOST http://localhost:1635/chequebook/deposit\\?amount\\=1000 | jq Copy {\"transactionHash\":\"0xedc80ebc89e6d719e617a50c6900c3dd5dc2f283e1b8c447b9065d7c8280484a\"} Copy You may then use Blockscout to track your transaction and make sure it completed successfully. Managing uncashed cheques# For the Bee process, the final step of earning BZZ is cashing a cheque. It is worth noting that a cheque is not yet actual BZZs. In Bee, a cheque, just like a real cheque, is a promise to hand over money upon request. In real life, you would present the cheque to a bank. In swarm life, we present the cheque to a smart-contract. Holding on to a swap-cheque is risky; it is possible that the owner of the chequebook has issued cheques worth more BZZ than is contained in their chequebook contract. For this reason, it is important to cash out your cheques every so often. With the set of API endpoints, as offered by Bee, it is possible to develop a script that fully manages the uncashed cheques for you. As an example, we offer you a very basic script, where you can manually cash out all cheques with a worth above a certain value. To use the script: Download and save the script: wget -O cashout.sh https://gist.githubusercontent.com/ralph-pichler/3b5ccd7a5c5cd0500e6428752b37e975/raw/cashout.sh Copy Make the file executable: chmod +x cashout.sh Copy List all uncashed cheques and cash out your cheques above a certain value: List: ./cashout.sh Copy info If running ./cashout.sh returns nothing, you currently have no uncashed cheques. Cashout all cheques: ./cashout.sh cashout-all Copy info Are you a Windows-user who is willing to help us? We are currently missing a simple cashout script for Windows. Please see theissue. info You can find the officially deployed smart-contract by the Swarm team in the swap-swear-and-swindle repository.","keywords":""},{"title":"Configuration","type":0,"sectionRef":"#","url":"docs/working-with-ant/configuration","content":"","keywords":""},{"title":"Important Configuration Changes","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#important-configuration-changes","content":"important Before starting Bee for the first time, there is some configuration to do! Make sure you consider updating the following recommended settings! "},{"title":"Full Node","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#full-node","content":"By default, Bee runs as a light node. To fully participate in the swarm, you must set the --full-node option to true. "},{"title":"Swap Endpoint","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#swap-endpoint","content":"In order to access the blockchain, your Bee must be connected to an XDAI blockchain node on the XDAI network. We recommend running your own XDAI Node, but if you prefer, you may also sign up to getblock.io API service and set your url to be https://stake.getblock.io/mainnet/?api_key=your-api-key "},{"title":"NAT Address","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#nat-address","content":"To enable others to connect to your node, you must broadcast your public IP and ensure Bee is accessible on the correct p2p port (default 1634). We recommend that you manually configure your external IP and check connectivityto ensure that your Bee is able to receive inbound connections from other peers. First determine your public IP address. curl icanhazip.com Copy 123.123.123.123 Copy Then configure your node, including your p2p port (default 1634). nat-addr: \"123.123.123.123:1634\" Copy "},{"title":"LevelDB Open File Descriptors Limit","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#leveldb-open-file-descriptors-limit","content":"Bee is designed to work on a lot of different hardware. To facilitate the exploration of this, we have given node operators access to leveldb's --db-open-files-limit. This influences the speed with which Bee can read and write to its database, and therefore its performance in forwarding and serving chunks. Some say setting this to much more than the default 200 leads to a much enhanced ability to participate in the swarm and get those BZZs! Share your experience in the #node-operators channel of our Discord server to help us make this process more automated in the future! "},{"title":"ENS Endpoint","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#ens-endpoint","content":"The ENS domain resolution system is used to host websites on Bee, and in order to use this your Bee must be connected to an Ethereum blockchain node on the main network. If you would like to browse the swarm We recommend you sign up to Infura's API service and set your --resolver-options=https://mainnet.infura.io/v3/your-api-key. "},{"title":"Specifying Configuration","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#specifying-configuration","content":""},{"title":"Configuration Priority","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#configuration-priority","content":"Configuration is processed in the following ascending order of preference: Command Line ArgumentsEnvironment VariablesConfiguration File "},{"title":"Command Line Arguments","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#command-line-arguments","content":"Run bee start --help in your Terminal to get the list of available command line arguments. "},{"title":"Environment variables","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#environment-variables","content":"Bee config may also be passed using environment variables. Environment variables are set as variables in your operating system's session or systemd configuration file. To set an environment variable, type the following in your terminal session. export VARIABLE_NAME=variableValue Copy Verify if it is correctly set by running echo $VARIABLE_NAME. All available configuration options are available as BEE prefixed, capitalised, and underscored environment variables. e.g. --api-addr becomes BEE_API_ADDR. "},{"title":"Configuration file","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#configuration-file","content":"Bee can also be configured by providing a YAML configuration file using the --config flag. bee start --config /home/<user>/bee-config.yaml Copy Automatically generate a config file# Configuration files can be easily generated by simply substituting the start command with printconfig when starting Bee using the command line. bee printconfig &> bee-config.yaml Copy This produces the following file contents, showing the default configuration of Bee: api-addr: :1633 block-hash: \"\" block-time: \"15\" bootnode: [] bootnode-mode: false cache-capacity: \"1000000\" clef-signer-enable: false clef-signer-endpoint: \"\" clef-signer-ethereum-address: \"\" config: /home/user/.bee.yaml cors-allowed-origins: [] data-dir: /home/user/.bee db-block-cache-capacity: \"33554432\" db-disable-seeks-compaction: false db-open-files-limit: \"200\" db-write-buffer-size: \"33554432\" debug-api-addr: :1635 debug-api-enable: false full-node: false gateway-mode: false global-pinning-enable: false help: false mainnet: false nat-addr: \"\" network-id: \"10\" p2p-addr: :1634 p2p-quic-enable: false p2p-ws-enable: false password: \"\" password-file: \"\" payment-early: \"10000000\" payment-threshold: \"100000000\" payment-tolerance: \"100000000\" postage-stamp-address: \"\" price-oracle-address: \"\" resolver-options: [] standalone: false swap-deployment-gas-price: \"\" swap-enable: true swap-endpoint: ws://localhost:8546 swap-factory-address: \"\" swap-initial-deposit: \"10000000000000000\" swap-legacy-factory-addresses: [] tracing-enable: false tracing-endpoint: 127.0.0.1:6831 tracing-service-name: bee transaction: \"\" verbosity: \"5\" warmup-time: 20m0s welcome-message: \"\" Copy "},{"title":"Configuring Bee Installed Using a Package Manager","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#configuring-bee-installed-using-a-package-manager","content":"Bee node's installed using package managers apt-get or yum are configured using a configuration file which is automatically generated during the installation process. To alter Bee's configuration, simply edit the configuration file as desired, and restart your Bee node using systemctl. "},{"title":"Linux","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#linux","content":"sudo vi /etc/bee/bee.yaml sudo systemctl restart bee Copy "},{"title":"MacOS","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#macos","content":"vi /usr/local/etc/swarm-bee/bee.yaml brew services restart swarm-bee Copy "},{"title":"Configuration Options","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#configuration-options","content":"Bee provides the following options to customise your node. "},{"title":"Global","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#global","content":"--config# default /home/<user>/.bee.yaml The location of a YAML configuration file containing configuration options. See configuration. "},{"title":"Start","type":1,"pageTitle":"Configuration","url":"docs/working-with-ant/configuration#start","content":"--api-addr# default :1633 The IP and port the API will serve HTTP requests from. Omitting the IP part of the address will cause the server to listen to all interfaces. Argument values are of the form '132.132.132.132:1633'. --block-time# default 15 The expected block time of the attached SWAP endpoint. --bootnode# default /dnsaddr/bootnode.ethswarm.org This is a multiaddrspecifying the Bee bootnodes used for bootstrapping the network. It can be multiple values. By default a node connects to the Swarm mainnet. When using a private or test network, network specific bootnodes must be set. Any Bee node in a network can act as a bootnode. --cache-capacity# default 1000000 The amount of disk space, in chunks, that is used for forwarding and uploading chunks. --clef-signer-enable# default false Set this to true to enable signing using Ethereum's Clef external signer. Clef is a new feature which requires a corresponding rules files or running in advanced mode to allow for auto-signing of handshakes and cheques. --clef-signer-endpoint# default default path for clef for each host operating system You may also specify a custom IPC file path for your Clef signer. --clef-signer-ethereum-address# default selects the clef address at index 0 Use this command to specify which Bee Clef address is used if you have imported multiple keys into Bee Clef. warning If you have multiple addresses imported into your instance of Bee Clef, you must specify your address for each node, including the first one, as addresses may been re-ordered during import. --cors-allowed-origins# default [] HTTP/WS origin domains or wildcards defining these, which the API will allow responses to, e.g. bee start --cors-allowed-origins=\"*\" bee start --cors-allowed-origins=\"https://website.ethswarm.org\" Copy --data-dir# default /home/<user>/.bee The location on your disk where Bee stores its data. Data in this directory will be required to restore a node state using the same key. This consists of the following three types of data. 1. Chunk Data (localstore)# This consists of chunks and files that you have pinned locally, cached chunks you have requested, or chunks within your radius of responsibility which you are responsible for serving to your peers. 2. State Data (statestore)# This is information about the local state of your Bee node and should be backed up. 3. Keystore Data (keys)# These files contain encrypted versions of your private key and should be backed up and kept private. danger Keep the key files in your keystore data directory safe! They are the cryptographic proof of your network identity and cannot be recovered. The next four options expose low-level configurations forLevelDB's Openfilemethod. Please let us know how you get on with tweaking these settings on your hardware in the#node-operators channel on ourDiscord server --db-block-cache-capacity# default 33554432 Corresponds to LevelDB BlockCacheCapacity (see above) --db-disable-seeks-compaction# default false Corresponds to LevelDB DisableSeeksCompaction (see above) --db-open-files-limit# default 200 info To accomodate less powerful hardware and operating systems, the db-open-files-limit is set deliberately low. We recommend that you try to increase it to nearer to 10000 or more if this is possible when using your hardware. Please let us know how you get on with tweaking these settings on your hardware in the #node-operators channel on our Discord server Corresponds to LevelDB OpenFilesCacheCapacity (see above) --db-write-buffer-size# default 33554432 Corresponds to LevelDB WriteBuffer (see above) --debug-api-addr# default :1635 The IP and port the Debug APIwill serve HTTP requests from. Omitting the IP part of the address will cause the server to listen to all requests. --debug-api-enable must be set to true. --debug-api-enable# default false Set this to true to enable access to the Debug API --full-node# default false Enable this by setting it to true to fully participate in serving and forwarding chunks to the network. --gateway-mode# default false Set this to true to disable a set of sensitive features in the API to ensure that it is safe to expose your api-addr to the public Internet. --global-pinning-enable# default false Enables the Global Pinning functionality when set to true. --mainnet# default false --nat-addr# default \"\" Sets the expected public IP. Normally this is generated automatically, but in certain circumstances it may be desirable to set it manually. --network-id# default 10 The network ID for which to accept new connections. Set to 1 for mainnet, 10 for testnet. --p2p-addr# default :1634 The IP and port to listen for p2p protocol messages. --p2p-quic-enable# default false --p2p-ws-enable# default false Enables web-sockets transport for p2p communications. --password# default \"\" Password used to decrypt Swarm identity keys. danger Passing passwords as command line arguments is insecure. Use a password file or environment variable in production environments. --password-file# default \"\" The path to a file that contains password for decrypting keys. The empty string assumes no file is presented. --payment-early# default 1000000000000 Amount in BZZ below the peers payment threshold which causes Bee to initiate settlement. --payment-threshold# default 10000000000000 The threshold in BZZ where you expect to get paid from your peers. --payment-tolerance# default 10000000000000 The excess debt above payment threshold in gBZZ where you disconnect from your peer. --postage-stamp-address# default automatically configured depending on network The address of the postage stamp contract on the Ethereum blockchain, used for buying batches of stamps. --resolver-options# default eth:0x00000000000C2E074eC69A0dFb2997BA6C7d2e1e@localhost:8545 ENS API endpoint for a TLD, with contract address. Multiple values can be provided. Settings should be provided in the format [tld:][contract-addr@]url A default top level domain and resolver contract address are provided, but an ENS/Geth endpoint must be provided to enable this functionality. --standalone# default false Set this flag if we would like the node not to try to connect to the network. Useful for development. --swap-enable# default true --swap-endpoint# default ws://localhost:8546 SWAP ethereum blockchain endpoint. Must be equipped with websockets. --swap-factory-address# default anointed contract for the current blockchain id --swap-initial-deposit# default 10000000000000000 --tracing-enable# default false Send tracing spans to the tracing service. More information how to configure and visualize tracing data is availablehere. --tracing-endpoint# default 127.0.0.1:6831 The URL where the tracing service listens for Thrift protocol UDP messages. --tracing-service-name# default bee Bee service identifier in tracing spans. --transaction# default \"\" As a spam prevention measure, for nodes which deployed their chequebook with v0.5.0 or before, specify transaction - the transaction hash of any Ethereum transaction on the XDAI networksent from the Bee node's Ethereum address. --verbosity# default info 0=silent, 1=error, 2=warn, 3=info, 4=debug, 5=trace --welcome-message# default \"\" Custom welcome message to be displayed to peers on succesful connection. "}]